{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Music Clustering\n",
    "* Prof: Dr. Johannes Maucher\n",
    "* Autor: Janina Mattes\n",
    "* Datum: 02.06.2020\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Musikdateien\n",
    "* Transcodierung von mp3 zu wav \n",
    "* Extraktion von Merkmalen in Musikdateien (Feature Extraction)\n",
    "* Optimierung mit dem genetischen Algorithmus\n",
    "* Selektion der aussagekräftigsten Merkmale (Feature Selection)\n",
    "* Clustering von Musikfiles (automatische Playlistgenerierung)\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "### Transcodierung von MP3 nach WAV und Merkmalsextraktion\n",
    "In diesem Versuch wird der MP3 Decoder [mpg123](http://www.mpg123.de/) eingesetzt. Installieren und testen sie diesen Decoder vor dem Versuch auf ihrem Rechner. Machen Sie sich zunächst mit dem in Kapitel [Gegebene Module zur Transcodierung und Feature Extraction](#Gegebene-Module-zur-Transcodierung-und-Feature-Extraction) aufgeführten Code vertraut. Versuchen Sie Funktion und Ablauf dieses Programms zu verstehen und beantworten Sie folgende Fragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Was versteht man unter den statistischen Größen _Mittelwert, Standardabweichung, Skewness und Kurtosis_?\n",
    "\n",
    "#### Mittelwert\n",
    "Mit dem Begriff Mittelwert (_auch Durchschnitt genannt_) ist in der Statistik meistens das _artithmetische Mittel_ gemeint. Der Mittelwert ist dabei eine Kennzahl für die zentrale Tendenz einer Verteilung. Das arithmetische Mittel ist rechnerisch die Summe der gegebenen Werte geteilt durch die Anzahl der Werte. Angewandt kann dies beispielsweise zum Berechnen einer Durchschnittsgeschwindigkeit werden. In diesem Fall würden die Werte als Geschwindigkeit interpretiert werden. Der _Erwartungswert_ einer Zufallsvariablen beschreibt hingegen die Zahl, die die Zufallsvariable im Mittel annimmt. \n",
    "\n",
    "#### Standardabweichung \n",
    "Die Standardabweichung ist ein Maß dafür, wie weit einzelne Datensätze verteilt sind. Mathematisch wird die Standardabweichung definiert als die mittlere quadratische Abweichung einer reellen Zufallsvariablen von ihrem Erwartungswert. Wenn alle Werte gleich sind, so ist die Standardabweichung Null, da diese von der Varianz abgeleitet ist. Das heißt je weiter Daten vertreut sind, desto höher ist die Standardabweichung. Je enger/näher Datensätze jedoch beieinander liegen, desto niedriger fällt die Standardabweichung aus. Es gibt zwei verschiedene Formeln der Anwendung, welche sich darin unterscheiden, dass nicht durch _n_, sondern durch _n-1_ geteilt wird.\n",
    "- die Standardabweichung für eine Stichprobe, wenn die Ergebnisse generalisierbar sein sollen. D.h. man möchte Ergebnisse erzielen, die es ermöglichen auf alle Menschen und nicht nur auf die ursprügnliche Versuchsgruppe _x_ Rückschlüsse zu ziehen.\n",
    "- die Standardabweichung für die Grundgesamtheit, wenn die Ergebnisse nicht verallgemeinert werden sollen. D.h. die Ergebnisse gelten nur für die Versuchsgruppe _x_.\n",
    "\n",
    "#### Skewness\n",
    "Die Schiefe (_eng. skewness_) gibt an, inwieweit eine Verteilungsfunktion sich zu einer Seite \"neigt\". Das heißt diese ist ein Maß für die Asymmetrie einer Verteilung. Der Wert kann dabei _positiv_ (Verteilungsfunktion tendiert nach rechts), _negativ_ (Verteilungsfunktion tendiert nach links), _null_ (Verteilungsfunktion ist symmetrisch) und _undefiniert_ (0/0) sein. Jede nicht-symmetrische Verteilungsfunktion ist schief.\n",
    "\n",
    "###### Eigenschaften einer unimodalen Verteilung**\n",
    "- linksschief (identisch mit dem Begriff rechtssteil) Verteilungen ist der Median größer als das arithmetische Mittel. \n",
    "- rechtsschief  (identisch mit dem Begriff linkssteil) Verteilungen ist der Modus kleiner als der Erwartungswert\n",
    "- Ist die Verteilungsfunktion symmetrisch, so ist das arithmetische Mittel gleich dem Median und die Verteilung wird eine Schiefe von 0 haben. \n",
    "\n",
    "#### Kurtosis\n",
    "Die Kurtosis (_dt. Wölbung_) ist ein Maß für die Steilheit einer Wahrscheinlichkeitsfunktion, oder Häufigkeitsverteilung. Verteilungen mit geringer Wölbung streuen relativ gleichmäßig; bei Verteilungen mit hoher Wölbung resultiert die Streuung mehr aus extremen, aber seltenen Ereignissen. Der Exzess gibt die Differenz der Wölbung der betrachteten Funktion zur Wölbung der Dichtefunktion einer normalverteilten Zufallsgröße an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Was beschreibt die Fourier-Transformierte eines zeitlich ausgedehnten Signals?\n",
    "\n",
    "#### Die Fourier Transformation\n",
    "Die Fourier-Transformation (genauer die kontinuierliche Fourier-Transformation  ist eine mathematische Methode aus dem Bereich der Fourier-Analysis, mit der kontinuierliche, aperiodische Signale in ein kontinuierliches Spektrum zerlegt werden. Die Funktion, die dieses Spektrum beschreibt, nennt man auch Fourier-Transformierte oder Spektralfunktion. Es handelt sich dabei um eine Integraltransformation, die nach dem Mathematiker Jean Baptiste Joseph Fourier benannt ist. Fourier führte im Jahr 1822 die Fourier-Reihe ein, die jedoch nur für periodische Signale definiert ist und zu einem diskreten Frequenzspektrum führt. Die Entwicklung einer Funktion in ihre _Fourier-Reihe_ wird harmonische Analyse genannt. Die Funktion wird dabei als Überlagerung von sinusförmigen, Schwingungen dargestellt. Ist die Funktion ein Eingangssignal eines LTI-Systems, kann das Ausgangssignal relativ einfach berechnet werden, da das Signals als Überlagerung von Eigenfunktionen des Systems vorliegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Mit welcher Samplingrate werden die WAV Dateien abgetastet?\n",
    "\n",
    "#### Abtastrate von WAV Dateien\n",
    "Die Abtastrate oder Abtastfrequenz, auch Samplingrate, Samplerate oder Samplingfrequenz, ist in der Signalverarbeitung die Häufigkeit, mit der ein Analogsignal (auch zeitkontinuierliches Signal genannt) in einer vorgegebenen Zeit abgetastet (das heißt, gemessen und in ein zeitdiskretes Signal umgewandelt) wird. Da es sich bei einer Abtastung immer um einen periodischen Vorgang handelt, ist ihre grundlegende Einheit das *Hertz* (abgekürzt: Hz), also Perioden pro Sekunde. \n",
    "- Ein Abtastvorgang pro Sekunde: 1 Hz = 1 S/s\n",
    "\n",
    "Die Waveform Audi File Format (_WAV_) ist eine von IBM und Missrn\n",
    "soft entwickeltes Containerformat für die Speicherung von Audiodaten. Die in den Containern enthaltenen  Dateien sind normalerweise unkomprimierte in _Pulscodemodulation (PCM)_ codierte Audiosignale für die Speicherung und Bearbeitung von Audio-Informationen. WAV-Dateien sind unkomprimiert und fehlerfrei, aber relativ groß. Ihre Größe ergibt sich aus der Abtastrate und der Samplingtiefe bei der Digitalisierung des analogen Audiosignals. Daraus ergibt sich bei einer standardmäßigen Abtastrate von **44,1 kHz** und einer Samplingtiefe von **16 Bit** eine Dateigröße von **5,3 Megabyte (MB) pro Minute** für ein Monosignal. Es sind allerdings auch andere Abtastraten und Sampletiefen möglich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Insgesamt werden 42 Merkmale pro Musiksequenz extrahiert. Beschreiben Sie kurz diese Merkmale\n",
    "\n",
    "#### Merkmalsextraktion bei WAV Dateien\n",
    "Die extrahierten Merkmale betreffen die Kurtuosis, ... Diese Merkmale liegen sowohl im Spektralbereich, als auch Merkmale im Zeitbereich.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching der Teilsequenzen\n",
    "\n",
    "1. Nachdem für jedes Musikstück die beiden Teilsequenzen in Form der extrahierten Merkmale vorliegen: Wie kann die Ähnlichkeit zwischen Teilsequenzen ermittelt \n",
    "werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Musikstücke, welche Teilsequencen in Vektoren umgewandelt und verglichen werden so müsste der erste und der zweite Teilstück gleich oder sehr ähnlich sein. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Welche Numpy- bzw. Scipy-Module können Sie für die Bestimmung der Ähnlichkeit zwischen Teilsequenzen einsetzen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetischer Algorithmus für die Merkmalsselektion\n",
    "\n",
    "1. Beschreiben Sie die Prozesschritte im genetischen Algorithmus [Genetischer Algorithmus](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html)\n",
    "2. In diesem Versuch wird davon ausgegangen, dass Merkmale dann gut sind, wenn durch sie die erste Teilsequenz eines Musikstücks durch einen ähnlichen Vektor wie die jeweils zweite Teilsequenz beschrieben wird. Wie kann mit dieser Annahme der genetische Algorithmus für die Merkmalsselektion angewandt werden. Unter Merkmalsselektion versteht man allgemein die Suche nach den $r$ besten Merkmalen aus einer Menge von insgesamt $R$ Merkmalen. In diesem Versuch werden initial $R=42$ Merkmale extrahiert, aus denen dann die besten $r<R$ Merkmale zu bestimmen sind. Überlegen Sie hierfür speziell wie die Fitnessfunktion, die Kreuzung und die Mutation zu realisieren sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering und Playlistgenerierung\n",
    "\n",
    "1. Wie kann mit einem hierarchischen Clustering der Musikfiles eine Menge von Playlists erzeugt werden, so dass innerhalb einer Playlist möglichst ähnliche Titel zu finden sind?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Gegebene Module zur Transcodierung und Feature Extraction\n",
    "Mit dem in diesem Abschnitt gegebenen Code werden die im Unterverzeichnis _BandCollection_ befindlichen mp3-Files zunächst in wave decodiert. Danach werden aus den wave Dateien Audiomerkmale erhoben.\n",
    "\n",
    "Von jedem Musikstück werden zwei disjunkte Teilsequenzen erhoben und von beiden Teilsequenzen jeweils ein Merkmalsvektor gebildet. Der Grund hierfür ist: Für die später folgende Bestimmung der wichtigsten Merkmale (Merkmalsselektion mit dem genetischen Algorithmus), wird angenommen dass Merkmale dann gut sind, wenn die aus ihnen gebildeten Merkmalsvektoren für Teilsequenzen des gleichen Musikstücks nahe beieinander liegen und die Merkmalsvektoren von Teilsequenzen unterschiedlicher Musikstücke weiter voneinander entfernt sind. In der Merkmalsselektion werden dann die Merkmale als relevant erachtet, für die diese Annahme zutrifft. \n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Stellen Sie im unten gegebenen Code die Verzeichnisse für Ihre Musikdateien (aktuell Unterverzeichnis _BandCollection_) und für den Ort Ihres _mpg123_ Decoders richtig ein.\n",
    "2. Die verwendete Musiksammlung sollte mindestens 5 verschiedene Interpreten möglichst unterschiedlicher Genres enthalten. Von jedem Interpret sollten mehrere Titel (evtl. ein ganzes Album) enthalten sein.\n",
    "3. Führen Sie den in diesem Abschnitt gegebenen Programmcode zur Audiofeature-Extraction aus. Damit werden für alle Musiksequenzen jeweils 42 Merkmale extrahiert. Die extrahierten Merkmalsvektoren der jeweils ersten Sequenz werden in das File _FeatureFileTrainingAllList1.csv_ geschrieben, die der zweiten Teilsequen in das File _FeatureFileTestAllList2.csv_. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Wave in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janina\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Wave\n",
    "!pip install pandas\n",
    "\n",
    "import subprocess\n",
    "import wave\n",
    "import struct\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(precision=2,suppress=True)\n",
    "\n",
    "#Names of features extracted in this module\n",
    "FeatNames=[\"amp1mean\",\"amp1std\",\"amp1skew\",\"amp1kurt\",\"amp1dmean\",\"amp1dstd\",\"amp1dskew\",\"amp1dkurt\",\"amp10mean\",\"amp10std\",\n",
    "           \"amp10skew\",\"amp10kurt\",\"amp10dmean\",\"amp10dstd\",\"amp10dskew\",\"amp10dkurt\",\"amp100mean\",\"amp100std\",\"amp100skew\",\n",
    "           \"amp100kurt\",\"amp100dmean\",\"amp100dstd\",\"amp100dskew\",\"amp100dkurt\",\"amp1000mean\",\"amp1000std\",\"amp1000skew\",\n",
    "           \"amp1000kurt\",\"amp1000dmean\",\"amp1000dstd\",\"amp1000dskew\",\"amp1000dkurt\",\"power1\",\"power2\",\"power3\",\"power4\",\n",
    "           \"power5\",\"power6\",\"power7\",\"power8\",\"power9\",\"power10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments(x):\n",
    "    mean = x.mean()\n",
    "    std = x.var()**0.5\n",
    "    skewness = ((x - mean)**3).mean() / std**3\n",
    "    kurtosis = ((x - mean)**4).mean() / std**4\n",
    "    return [mean, std, skewness, kurtosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature category 2: Frequency domain parameters\n",
    "def fftfeatures(wavdata):\n",
    "    f = numpy.fft.fft(wavdata)\n",
    "    f = f[2:int(f.size / 2 + 1)]\n",
    "    f = abs(f)\n",
    "    total_power = f.sum()\n",
    "    f = numpy.array_split(f, 10)\n",
    "    return [e.sum() / total_power for e in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the entire feature vector per music-file\n",
    "def features(x):\n",
    "    x = numpy.array(x)\n",
    "    f = []\n",
    "\n",
    "    xs = x\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 10).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 100).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 1000).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    f.extend(fftfeatures(x))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(wav_file):\n",
    "    \"\"\"Returns two chunks of sound data from wave file.\"\"\"\n",
    "    w = wave.open(wav_file)\n",
    "    n = 60 * 10000\n",
    "    if w.getnframes() < n * 3:\n",
    "        raise ValueError('Wave file too short')\n",
    "    #For each music file 2 sequences, each containing n frames are subtracted. The first sequence starts at postion n,\n",
    "    #the second sequence starts at postion 2n. The reason for extracting 2 subsequences is, that later on we like to\n",
    "    #find the best features and in this exercise we assume that good features have the property that they are similar for 2 subsequences\n",
    "    #of the same song, but differ for subsequences of different songs.\n",
    "    w.setpos(n)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data1 = struct.unpack('%dh' % n, frames)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data2 = struct.unpack('%dh' % n, frames)\n",
    "    return wav_data1, wav_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chunk_features(mp3_file):\n",
    "    \"\"\"Return feature vectors for two chunks of an MP3 file.\"\"\"\n",
    "    # Extract MP3 file to a mono, 10kHz WAV file\n",
    "    #mpg123_command = 'C:\\Program Files (x86)\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    #mpg123_command = 'C:\\\\Program Files (x86)\\\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    mpg123_command = 'C:\\Program Files (x86)\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    out_file = 'temp.wav'\n",
    "    cmd = mpg123_command % (out_file, mp3_file)\n",
    "    temp = subprocess.call(cmd)\n",
    "    # Read in chunks of data from WAV file\n",
    "    wav_data1, wav_data2 = read_wav(out_file)\n",
    "    # We'll cover how the features are computed in the next section!\n",
    "    return numpy.array(features(wav_data1)), numpy.array(features(wav_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/BandCollection\\Adele\\01 Hometown Glory.mp3\n",
      "--------------------Adele\\01 Hometown Glory.mp3--------------------\n",
      "../data/BandCollection\\Adele\\02 I'll Be Waiting.mp3\n",
      "--------------------Adele\\02 I'll Be Waiting.mp3--------------------\n",
      "../data/BandCollection\\Adele\\03 Don't You Remember.mp3\n",
      "--------------------Adele\\03 Don't You Remember.mp3--------------------\n",
      "../data/BandCollection\\Adele\\04 Turning Tables.mp3\n",
      "--------------------Adele\\04 Turning Tables.mp3--------------------\n",
      "../data/BandCollection\\Adele\\05 Set Fire To The Rain.mp3\n",
      "--------------------Adele\\05 Set Fire To The Rain.mp3--------------------\n",
      "../data/BandCollection\\Adele\\06 If It Hadn't Been For Love.mp3\n",
      "--------------------Adele\\06 If It Hadn't Been For Love.mp3--------------------\n",
      "../data/BandCollection\\Adele\\07 My Same.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Adele\\08 Take It All.mp3\n",
      "--------------------Adele\\08 Take It All.mp3--------------------\n",
      "../data/BandCollection\\Adele\\09 Rumour Has It.mp3\n",
      "--------------------Adele\\09 Rumour Has It.mp3--------------------\n",
      "../data/BandCollection\\Adele\\10 Right As Rain.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Adele\\11 One And Only.mp3\n",
      "--------------------Adele\\11 One And Only.mp3--------------------\n",
      "../data/BandCollection\\Adele\\12 Lovesong.mp3\n",
      "--------------------Adele\\12 Lovesong.mp3--------------------\n",
      "../data/BandCollection\\Adele\\13 Chasing Pavements.mp3\n",
      "--------------------Adele\\13 Chasing Pavements.mp3--------------------\n",
      "../data/BandCollection\\Adele\\14 I Can't Make You Love Me.mp3\n",
      "--------------------Adele\\14 I Can't Make You Love Me.mp3--------------------\n",
      "../data/BandCollection\\Adele\\15 Make You Feel My Love.mp3\n",
      "--------------------Adele\\15 Make You Feel My Love.mp3--------------------\n",
      "../data/BandCollection\\Adele\\16 Someone Like You.mp3\n",
      "--------------------Adele\\16 Someone Like You.mp3--------------------\n",
      "../data/BandCollection\\Adele\\17 Rolling In The Deep.mp3\n",
      "--------------------Adele\\17 Rolling In The Deep.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\01 So What'cha Want.mp3\n",
      "--------------------BeastieBoys\\01 So What'cha Want.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\02 Brass Monkey.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\03 Ch-Check It Out.mp3\n",
      "--------------------BeastieBoys\\03 Ch-Check It Out.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\04 No Sleep Till Brooklyn.mp3\n",
      "--------------------BeastieBoys\\04 No Sleep Till Brooklyn.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\05 Hey Ladies.mp3\n",
      "--------------------BeastieBoys\\05 Hey Ladies.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\06 Pass the Mic.mp3\n",
      "--------------------BeastieBoys\\06 Pass the Mic.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\07 An Open Letter to NYC.mp3\n",
      "--------------------BeastieBoys\\07 An Open Letter to NYC.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\08 Root Down.mp3\n",
      "--------------------BeastieBoys\\08 Root Down.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\09 Shake Your Rump.mp3\n",
      "--------------------BeastieBoys\\09 Shake Your Rump.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\10 Intergalactic.mp3\n",
      "--------------------BeastieBoys\\10 Intergalactic.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\11 Sure Shot.mp3\n",
      "--------------------BeastieBoys\\11 Sure Shot.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3\n",
      "--------------------BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\13 Triple Trouble.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\14 Sabotage.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\15 Fight for Your Right.mp3\n",
      "--------------------BeastieBoys\\15 Fight for Your Right.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\01 Smooth Criminal 1.mp3\n",
      "--------------------Garrett\\01 Smooth Criminal 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\02 Who Wants to Live Forever_ 1.mp3\n",
      "--------------------Garrett\\02 Who Wants to Live Forever_ 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\03 Clair de Lune 1.mp3\n",
      "--------------------Garrett\\03 Clair de Lune 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3\n",
      "--------------------Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\05 Summertime 1.mp3\n",
      "--------------------Garrett\\05 Summertime 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\06 Brahms Hungarian Dance No. 5 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\07 Chelsea Girl 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\08 Summer 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\09 O Mio Babbino Caro 1.mp3\n",
      "--------------------Garrett\\09 O Mio Babbino Caro 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\10 Air.mp3\n",
      "--------------------Garrett\\10 Air.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\11 Thunderstruck.mp3\n",
      "--------------------Garrett\\11 Thunderstruck.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\12 New Day.mp3\n",
      "--------------------Garrett\\12 New Day.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\13 Ain't No Sunshine.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\14 Rock Prelude.mp3\n",
      "--------------------Garrett\\14 Rock Prelude.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\15 Winter Lullaby.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\16 Little Wing.mp3\n",
      "--------------------Garrett\\16 Little Wing.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\01 Born to Die.mp3\n",
      "--------------------LanaDelRey\\01 Born to Die.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\02 Off to the Races.mp3\n",
      "--------------------LanaDelRey\\02 Off to the Races.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\03 Blue Jeans (Remastered).mp3\n",
      "--------------------LanaDelRey\\03 Blue Jeans (Remastered).mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\04 Video Games (Remastered).mp3\n",
      "--------------------LanaDelRey\\04 Video Games (Remastered).mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\05 Diet Mountain Dew.mp3\n",
      "--------------------LanaDelRey\\05 Diet Mountain Dew.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\06 National Anthem.mp3\n",
      "--------------------LanaDelRey\\06 National Anthem.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\07 Dark Paradise.mp3\n",
      "--------------------LanaDelRey\\07 Dark Paradise.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\08 Radio.mp3\n",
      "--------------------LanaDelRey\\08 Radio.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\09 Carmen.mp3\n",
      "--------------------LanaDelRey\\09 Carmen.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\10 Million Dollar Man.mp3\n",
      "--------------------LanaDelRey\\10 Million Dollar Man.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\11 Summertime Sadness.mp3\n",
      "--------------------LanaDelRey\\11 Summertime Sadness.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\12 This Is What Makes Us Girls.mp3\n",
      "--------------------LanaDelRey\\12 This Is What Makes Us Girls.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\01 Bombtrack.mp3\n",
      "--------------------RageAgainstTheMachine\\01 Bombtrack.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\02 Killing In the Name.mp3\n",
      "--------------------RageAgainstTheMachine\\02 Killing In the Name.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\03 Take the Power Back.mp3\n",
      "--------------------RageAgainstTheMachine\\03 Take the Power Back.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\04 Settle for Nothing.mp3\n",
      "--------------------RageAgainstTheMachine\\04 Settle for Nothing.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\05 Bullet In the Head.mp3\n",
      "--------------------RageAgainstTheMachine\\05 Bullet In the Head.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\06 Know Your Enemy.mp3\n",
      "--------------------RageAgainstTheMachine\\06 Know Your Enemy.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\07 Wake Up.mp3\n",
      "--------------------RageAgainstTheMachine\\07 Wake Up.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\08 Fistful of Steel.mp3\n",
      "--------------------RageAgainstTheMachine\\08 Fistful of Steel.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\09 Township Rebellion.mp3\n",
      "--------------------RageAgainstTheMachine\\09 Township Rebellion.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\10 Freedom.mp3\n",
      "--------------------RageAgainstTheMachine\\10 Freedom.mp3--------------------\n"
     ]
    }
   ],
   "source": [
    "fileList=[]\n",
    "featureList1=[]\n",
    "featureList2=[]\n",
    "#Specify the name of the directory, which contains your MP3 files here.\n",
    "# This directory should contain for each band/author one subdirectory, which contains all songs of this author\n",
    "for path, dirs, files in os.walk('../data/BandCollection'):\n",
    "    #print '-'*10,dirs,files\n",
    "    for f in files:\n",
    "        if not f.endswith('.mp3'):\n",
    "            # Skip any non-MP3 files\n",
    "            continue\n",
    "        mp3_file = os.path.join(path, f)\n",
    "        print(mp3_file)\n",
    "        # Extract the track name (i.e. the file name) plus the names\n",
    "        # of the two preceding directories. This will be useful\n",
    "        # later for plotting.\n",
    "        tail, track = os.path.split(mp3_file)\n",
    "        tail, dir1 = os.path.split(tail)\n",
    "        tail, dir2 = os.path.split(tail)\n",
    "        # Compute features. feature_vec1 and feature_vec2 are lists of floating\n",
    "        # point numbers representing the statistical features we have extracted\n",
    "        # from the raw sound data.\n",
    "        try:\n",
    "            feature_vec1, feature_vec2 = compute_chunk_features(mp3_file)\n",
    "        except:\n",
    "            print(\"Error: Chunk Features failed\")\n",
    "            continue\n",
    "        #title=str(track)\n",
    "        title=str(dir1)+'\\\\'+str(track)\n",
    "        print('-'*20+ title +'-'*20) \n",
    "        #print \"       feature vector 1:\",feature_vec1\n",
    "        #print \"       feature vector 2:\",feature_vec2\n",
    "        fileList.append(title)\n",
    "        featureList1.append(feature_vec1)\n",
    "        featureList2.append(feature_vec2)\n",
    "\n",
    "# Write feature vecotrs of all music files to pandas data-frame\n",
    "MusicFeaturesTrain = pd.DataFrame(index=fileList, data=numpy.array(featureList1), columns=FeatNames)\n",
    "MusicFeaturesTrain.to_csv(\"FeatureFileTrainingAllList1.csv\")\n",
    "\n",
    "MusicFeaturesTest = pd.DataFrame(index=fileList, data=numpy.array(featureList2), columns=FeatNames)\n",
    "MusicFeaturesTest.to_csv(\"FeatureFileTestAllList2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching der Teilsequenzen\n",
    "In diesem Abschnitt soll ein Verfahren implementiert werden, mit dem die Übereinstimmung der ersten Teilsequenz eines Musikstücks mit den zweiten Teilsequenzen aller anderen Musikstücke berechnet werden kann.\n",
    "\n",
    "**Aufagben:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install prettyprint\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lesen Sie die im vorigen Teilversuch angelegten zwei csv-Dateien in jeweils einen eigenen Pandas Dataframe ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = pd.read_csv(\"FeatureFileTrainingAllList1.csv\", sep=\",\", header=0, names=FeatNames)\n",
    "df_test_features = pd.read_csv(\"FeatureFileTestAllList2.csv\", sep=\",\", header=0, names=FeatNames)\n",
    "#pp.pprint(df_train_features.head(5))\n",
    "#pp.pprint(df_test_features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Skalieren Sie beide Teilsequenzmengen, so dass alle Merkmale eine Standardabweichung von 1 aufweisen. Z.B. mit [http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\janina\\anaconda3\\envs\\conda_env\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.preprocessing.scale(X, *, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "# returns a numpy array\n",
    "train_features_scaled = preprocessing.scale(df_train_features)\n",
    "test_features_scaled = preprocessing.scale(df_test_features)\n",
    "\n",
    "##pp.pprint(train_features_scaled)\n",
    "##pp.pprint(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pp.pprint('Mean value \\n {0}'.format(train_features_scaled.mean(axis=0)))\n",
    "##pp.pprint('Standard deviation \\n {0}'.format(train_features_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pp.pprint('Mean value \\n {0}'.format(test_features_scaled.mean(axis=0)))\n",
    "##pp.pprint('Standard deviation \\n {0}'.format(test_features_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = pd.DataFrame(data=train_features_scaled, index=df_train_features.index, columns=df_train_features.columns)\n",
    "df_test_features = pd.DataFrame(data=test_features_scaled, index=df_test_features.index, columns=df_test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp.pprint('The train features Dataframe {}'.format(train))\n",
    "#pp.pprint('The test features Dataframe {}'.format(df_test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die merkmalsausprägung von Objekten unterliegt _Streuungen_. Hierdurch kann eine Distanz _d{ij} zwischen den Objekten durch die Mermale dominiert werden, die eine entsprechend große Streuung besitzen. Dieser Umstand ist besonders zu berücksichtigen, wenn zwischen den Objektmerkmalen, deutliche Größenunterschiede bestehen. Um die Streuung zu berücksichtigen, werden die Merkmale _skaliert_. Wird die Distanz über die _L-2_ Norm bestimmt, kann die Skalierung über die **Standardabweichung** _s_ durchgeführt werden. Dazu wird _F2_ um die quadratische Standardabweichung _s_ ergänzt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnung der skalierten Distanz\n",
    "**3.1 Euklidsche Distanz**: Bestimmen Sie zu jeder Teilsequenz aus der Datei _FeatureFileTrainingAllList1.csv_ die euklidische Distanz zu allen Teilsequenzen aus der Datei _FeatureFileTestAllList2.csv_ und schreiben Sie diese Distanzen in eine aufsteigend geordnete Liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euklidische Distanz zu allen Teilsequenzen\n",
    "def calcEuclideandDist(df_one, df_two):\n",
    "    euclid_dist_dict = {}\n",
    "    for index_one, row_one in df_one.iterrows():\n",
    "        euclid_dist_list = []\n",
    "        for index_two, row_two in df_two.iterrows():\n",
    "            euclid_dist_list.append([distance.euclidean(row_one, row_two), index_two])\n",
    "        euclid_dist_list.sort()\n",
    "        euclid_dist_dict[index_one] = euclid_dist_list\n",
    "    return euclid_dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "euclid_dist_dict = calcEuclideandDist(df_train_features, df_test_features)\n",
    "print(len(euclid_dist_dict))\n",
    "#pp.pprint(euclid_dist_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Korrelative Distanz**: Schreiben Sie auch die zugehörigen Argumente (Teilsequenzen) in eine geordnete Liste, sodass für jede Teilsequenz aus _FeatureFileTrainingAllList1.csv_ die am nächsten liegende Teilsequenz aus _FeatureFileTestAllList2.csv_ an erster Stelle steht, die zweitnächste Teilsequenz an zweiter usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zugehörige Argumente für beide Teilsequenzen\n",
    "def calcCorrelationDist(df_one, df_two):\n",
    "    cor_dist_dict={}\n",
    "    for index_one, row_one in df_one.iterrows():\n",
    "        cor_dist_list = []\n",
    "        for index_two, row_two in df_two.iterrows():\n",
    "            cor_dist_list.append([distance.correlation(row_one, row_two), index_two])\n",
    "        cor_dist_list.sort()\n",
    "        cor_dist_dict[index_one] = cor_dist_list\n",
    "    return cor_dist_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "cor_dist_dict = calcCorrelationDist(df_train_features, df_test_features)\n",
    "print(len(cor_dist_dict))\n",
    "#pp.pprint(cor_dist_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnung des Mittleren Rangs\n",
    "4. Bestimmen Sie über alle Teilsequenzen aus _FeatureFileTrainingAllList1.csv_ den **mittleren Rang** an dem die zugehörige zweite Teilsequenz erscheint. Liegt z.B. für die erste Teilsequenz des Musikstücks A die zweite Teilsequenz nur an fünfter Stelle der geordneten nächsten Nachbarliste. Dann würde diese Teilsequenz mit dem Rang 5 in den Mittelwert einfließen.\n",
    "\n",
    "Hinweis: Werden die verkürzten Files mit 50 anstelle von 60 genommen. Aufgrund dieser geänderten Datengrundlage sind die aktuellen Abweichungen vorhanden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanRank(dist_dict):\n",
    "    # initialize the dict\n",
    "    rank_list = []\n",
    "    for seq_one, seq_one_val in dist_dict.items():\n",
    "        for index, seq_two_val in enumerate(seq_one_val):\n",
    "            if seq_one == seq_two_val[1]:\n",
    "                rank_list.append(index + 1) # shift by one as rank zero isnt allowed\n",
    "    # calculate mean\n",
    "    mean_rank = mean(rank_list)\n",
    "    return mean_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.65"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_mean_rank = calcMeanRank(cor_dist_dict)\n",
    "cor_mean_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bestimmen Sie jetzt den mittleren Rang, für den Fall, dass _correlation_ anstelle _euclidean_ als Ähnlichkeitsmaß verwendet wird. Welches Ähnlichkeitsmaß ist für diese Anwendung zu bevorzugen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5166666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euc_mean_rank = calcMeanRank(euclid_dist_dict)\n",
    "euc_mean_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die euklidische Distanz wird auch _L2-Norm_ genannt und ist eine Variante der sogenannten Minkowski-Metrik zur Berechnung von distanzen zwischen Vektoren (Punkte) in einem höherdimensionalen Raum. Die Korrelation ist ein Maß für den statistischen Zusammenhang zwischen zwei Datensätzen. Das Ähnlichkeitsmaß der Korrelation ist in diesem Fall für die Anwendung zu bevorzugen, da dies eine bessere Aussage über die tatsächliche Ähnlichkeit der Formen zwischen den Vektoren erlaubt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Diskutieren Sie das Ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Signalverarbeitung wird häufig die Metrik der _Korrelation_ oder _Cross-Correlation_ eingesetzt. Dabei ist ein Wert größer als 0.8 anzustreben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalsauswahl mit dem genetischen Algorithmus\n",
    "In diesem Abschnitt soll unter Anwendung eines selbst zu implementierenden genetischen Algorithmus eine Untermenge wichtiger Merkmale aus den insgesamt 42 angelegten Merkmalen berechnet werden.\n",
    "Als Vorlage kann hierfür die Implementierung für die [Lösung des TSP Problems](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html) herangezogen werden. Anzupassen sind dann jedoch mindestens die Fitness-Funktion, die Kreuzungs- und die Mutationsfunktion. \n",
    "\n",
    "#### Der Genetische Algorithmus\n",
    "Ein Genetischer Algorithmus (GA) ist eine Such-Heuristik, welche durch _Charls Darwin's_ Theorie der natürlichen Evolution inspiriert wurde. Dieser reflektiert den Prozess, in welchem eine natürliche Selektion der besten (_fittest_) Individuen einer Population für eine Reproduktion selektiert werden. Genetische Algorithmen (GA) sind sehr gut für Probleme in der Suche, als auch für Optimierungen einzusetzen. Ein Beispiel hierfür ist der Einsatz eines _GA_, um eine Lösung für das \"Travelling Salesman Problem\" (TSP) zu finden. \n",
    "Für die Erkundung der besten Merkmale in diesem Fall werden die einzelnen Elemente des GA auf die Problemstellung wie folgt übertragen: \n",
    "\n",
    "* **Gene**: Einzelnes Element eines Merkmals, bzw. ein Satz an Parametern (Variablen).\n",
    "* **Individual/Chromosome**: Ein Chromosom ist eine Zusammensetzung von Genen. In diesem Fall ein einzelnes Merkmal, welches die Bedingungen erfüllt. \n",
    "* **Population**: Eine Sammlung möglicher Merkmale.\n",
    "* **Parents**: Zwei Merkmale, welche kombiniert werden, um ein neues Merkmal zu generieren.\n",
    "* **Mating Pool**: Eine Sammlung an Elternteilen, welche dazu verwendet werden, eine neue Population (nächste Generation) zu generieren.\n",
    "* **Fitness**: Eine Funktion, welche die Güte der Mermale anhand ihres _mittleren Rangs_ bewertet.\n",
    "* **Mutation**: Eine Möglichkeit Variationen in der Population zu erzeugen, durch zufälliges austauschen von Elementen der Merkmale.\n",
    "* **Elitism**: Eine Möglichkeit die besten Individuen in die nächste Generation zu übertragen. \n",
    "\n",
    "Der hier dargestellte Genetische Algorithmus (GA) wird die folgenden Schritte ausführen:\n",
    "\n",
    "1. Erzeugung einer initialen, zufälligen Population.\n",
    "2. Fitness der Individuen (_Chromosomen_) innerhalb der Population berechnen.\n",
    "3. Selektion des _Mating Pools_, d.h. der fittesten Individuen.\n",
    "4. Kreuzung zur Erzeugung einer neuen Generation.\n",
    "5. Mutation.\n",
    "6. Austausch gegen die neue Population.\n",
    "7. Wiederhole von Schritt 1 bis 6, bis die Abbruchbedingung erfüllt ist.\n",
    "\n",
    "**Aufgaben:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetischer Algorithmus für die Music Feature Selection\n",
    "\n",
    "1. Implementieren Sie die die Merkmalsauswahl mit dem genetischen Algorithmus entsprechend der o.g. Beschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas --upgrade\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random, operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitness-Funktion\n",
    "Die Fitness der Population wird mittels des _mittleren Rangs_, wie im vorherigen Abschnitt berechnet. Je geringer die Größe des mittleren Ranges, desto höher die Bedeutsamkeit der ausgewählten Merkmale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fitness\n",
    "def fitness(df_train, df_test):\n",
    "    euclead_dist = calcEuclideandDist(df_train, df_test)    \n",
    "    return calcMeanRank(euclead_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selektions-Funktion\n",
    "Zur Selektion des _Mating Pools_, d.h. der Elternteile, welche zur Erzeugung der nächsten Generation herangezogen werden sollen, können verschiedene Methoden angewandt werden. Die populärsten Methoden sind _fitness proporionate selection_, ähnlich eines Roulette Rades oder die _tournament selection_. Eine weitere Möglichkeit der Selektion ist die Methode des _elitism_. Hierbei werden die höchst Performer in der Population gegenüber der gesamten Performance der Population bewertet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(popRanked, eliteSize):\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matingPool(population, selection):\n",
    "    return matingPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kreuzungsfunktion\n",
    "Die Kreuzung mittels _crossover_ hat verschiedene Arten an Kreuzungsverfahren. Diese können sein: _blend, one point, two points, uniform_. Mittels __crossover_ soll die nächste Generation aus der selektierten Elternpopulation generiert werden. Man nennt dies auch \"_breeding_\". In diesem Fall wird eine Funktion des _ordered crossover_ verwendet. Dabei werden zufällige Elemente (_Gene_) des ersten Elternteils ausgewählt und mit Elementen / Genen des zweiten Elternteils aufgefüllt, ohne diese zu duplizieren.\n",
    "\n",
    "* Kreuzungsfunktion wie in der KI Vorlesung beim Travelling Salesman Problem. \n",
    "* Man legt einen Kreuzungspunkt fest, nimmt dann für das erste Kind den ersten Kopf wie im Elternteil und für den Tail des ersten Kindes, scannt man den ersten Elternteil und übernimmt die Features die noch nicht drin sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    return child    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generierung der neuen Generation (_offspring population_). Zuerst wird hierbei _elitism_ verwendet, um die besten Merkmale zu erhalten, um diese dann mittels _crossover_ aufzufüllen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossoverPopulation(matingpool, eliteSize):\n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutationsfunktion\n",
    "Es gibt verschiedene Varianten, um Mutation zu erzeugen. Diese sind unter Anderem: _it flip, swap, inverse, uniform, non-uniform, gaussian, shrink_. Mutation hält eine wichtige Funktion für GAs inne, denn diese hilft lokale Komvergenz (_local convergence_), durch das Einführen neuer, noch unbekannter Merkmale, zu vermeiden. Die Einführung neuer Merkmale ermöglicht es einen noch unbekannten Lösungsraum zu erkunden. Da einzelne Merkmale nicht einfach herausgelöscht werden dürfen, wird hier die Methode des _swap mutation_ angewandt. Dies bedeutet, dass mit einer geringen Wahrscheinlichkeit verschiedene Merkmale ihre Lokation austauschen (_swap_) werden. Für ein Individuum kann dies mittels der folgenden Funktion erzeugt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual, mutationRate):\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutatePopulation(population, mutationRate):\n",
    "    return mutatedPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generation der Population\n",
    "Eine zufällige Population (_set of features_) wird aus der gesamten Population mittels _df.samples()_ Funktion herausgelöst. Diese dient als initiale Population für den GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(popSize, featureAmount, featureNames):\n",
    "    # initialize population\n",
    "    population = np.zeros((popSize, featureAmount))\n",
    "    # important use permutation\n",
    "    for i in range(popSize):\n",
    "        population[i, 0:featureAmount]=np.random.permutation(len(featureNames))[:featureAmount]\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeugung der nächsten Generation\n",
    "Eine neue Generation soll mittels der unten aufgeführten Funktion generiert werden. Hierzu werden alle Distanzen, bzw. die Fitness der Merkmale mittels dem _mittleren Rang_ bewertet. Hierauf werden potentielle Eltern aus der Population ausgewählt und ein _Mating Pool_ definiert. Aus diesem kann dann eine neue Generation mittels Kreugung (_crossover_) und Mutation (_mutation_) generiert werden. \n",
    "\n",
    "#### Anmerkung\n",
    "Es ist wichtig zu beachten, dass eine Population eine feste Größe behält. Einzelne, Individuen (_Chromosome_) werden nur gegen fittere Individuen ausgetauscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_population(popRanked, currentGen, eliteSize, mutationRate):\n",
    "    return nextGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetischer Algorithmus\n",
    "\n",
    "Die Populationsgröße, die Anzahl der auszuwählenden Merkmale und die Anzahl der Iterationen sollen als Parameter einstellbar sein.\n",
    "Der Fitnesswert des besten Individuums in der Population soll in jeder Iteration gespeichert werden. Der Verlauf dieses besten Fitness-Wertes über den Fortlauf der Iterationen soll graphisch ausgegeben werden.\n",
    "\n",
    "Ein Pandas Frame, der nur die berechneten wichtigsten Merkmale aus _FeatureFileTrainingAllList1.csv_ enthält soll angelegt und in die csv Datei _subFeaturesTrain1.csv_ geschrieben werden.\n",
    "\n",
    "#### Pseudo Code\n",
    "```\n",
    "START\n",
    "Generate the initial population\n",
    "Compute fitness\n",
    "REPEAT\n",
    "    Selection\n",
    "    Crossover\n",
    "    Mutation\n",
    "    Compute fitness\n",
    "UNTIL population has converged\n",
    "STOP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastEuclidean(x,y):\n",
    "    z=y-x\n",
    "    return math.sqrt(np.dot(z,z))\n",
    "                     \n",
    "def mid_rank(df_train,df_test,similarity): \n",
    "    FeatureFileTrainingDF_scaled = preprocessing.scale(df_train,0)\n",
    "    FeatureFileTestAllDF_scaled = preprocessing.scale(df_test,0)\n",
    "    size = len(FeatureFileTestAllDF_scaled)\n",
    "    rank = 0\n",
    "    ranklist = np.zeros(size)\n",
    "    dct_dist = np.zeros(size)\n",
    "    for i,k in enumerate(FeatureFileTrainingDF_scaled):  \n",
    "        for j,l in enumerate(FeatureFileTestAllDF_scaled):            \n",
    "            dist = similarity(k, l)\n",
    "            dct_dist[j] = dist\n",
    "            \n",
    "        dct_index = np.argsort(dct_dist)\n",
    "        ranklist[i] = np.where(dct_index == i)[0][0]+1    \n",
    "    rank = sum(ranklist)/len(ranklist)\n",
    "    return(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def genAlg(iterations, popSize, anzahlMerkmale, mutationPopulation, label):\n",
    "    kreuzPopulation = 0.99\n",
    "    \n",
    "    bestDist = np.zeros(iterations)\n",
    "    fitness=np.zeros(popSize)\n",
    "    featureNames_fit = np.array(FeatNames)\n",
    "    population = np.zeros((popSize, anzahlMerkmale))\n",
    "    #display(population)\n",
    "    pop = generate_population(popSize, anzahlMerkmale, FeatNames)\n",
    "    \n",
    "    for j in range(iterations):\n",
    "            #Fitnessberechnung:##############################################\n",
    "            for k in range(popSize):\n",
    "                selection = featureNames_fit[population[k].astype(int)]\n",
    "                #print(selection)\n",
    "                df1_temp = df_train_features[selection]\n",
    "                df2_temp = df_test_features[selection]\n",
    "                midRank_temp = mid_rank(df1_temp, df2_temp,  fastEuclidean)\n",
    "                fitness[k] = midRank_temp\n",
    "                #print(midRank_temp)\n",
    "            sortedIndex = fitness.argsort(axis=0)#Indizees der nach ansteigenden Distanzen sortieren\n",
    "            sortedDist = fitness[sortedIndex] # die ansteigend sortiere Distanzen\n",
    "            #print(\"sortedIndex\", sortedIndex)\n",
    "            #print(\"sortedCost\", sortedDist)\n",
    "            bestDist[j] = sortedDist[0] #kleinste Distanz der Iteration abspeichern    \n",
    "            sortedPopulation = population[sortedIndex].astype(int) #sortierung der Population nach ansteigender Distanz    \n",
    "            #print(\"sortedPopulation\", sortedPopulation)\n",
    "            invertedDist = 1/sortedDist #Berechnung der Fitness aus der Distanz\n",
    "            #invertedDist enthält die berechneten Fitness Werte\n",
    "            #print(\"invertedDist\", invertedDist)\n",
    "            #################################################################\n",
    "            \n",
    "            #Selection#######################################################\n",
    "            invertedDistSum = invertedDist.sum()\n",
    "            #print(\"invertedDistSum:\", invertedDistSum)\n",
    "            rn1 = invertedDistSum * np.random.rand() # Zufallszahl ziwschen 0 und 1 * invertedDistSum\n",
    "            #print(\"rn1\", rn1)\n",
    "            found1 = False\n",
    "            index = 1\n",
    "            while not found1:\n",
    "                #print(\"invertedDist[:index].sum(axis=0)\", invertedDist[:index].sum(axis=0))\n",
    "                if rn1 < invertedDist[:index].sum(axis=0): #sum(axis=0): entlang der column summieren\n",
    "                    #print(\"gefunden. index ist:\", index)\n",
    "                    found1=index\n",
    "                else:\n",
    "                    index+=1\n",
    "            found1 = found1-1\n",
    "            equal=True\n",
    "            while equal:\n",
    "                rn2=invertedDistSum * np.random.rand()\n",
    "                #print(\"rn2\", rn2)\n",
    "                found2 = False\n",
    "                index=1\n",
    "                while not found2:\n",
    "                    #print(\"invertedDist[:index].sum(axis=0)\", invertedDist[:index].sum(axis=0))\n",
    "                    if rn2 < invertedDist[:index].sum(axis=0):\n",
    "                        #print(\"gefunden. index ist:\", index)\n",
    "                        found2 = index\n",
    "                    else:\n",
    "                        index+=1\n",
    "                found2=found2-1\n",
    "                if found2 != found1:\n",
    "                    equal = False\n",
    "                #print(\"beides equal?\", equal)\n",
    "            #print(\"ok, weiter gehts\")\n",
    "            parent1 = sortedPopulation[found1]\n",
    "            #print(\"parent1\", parent1)\n",
    "            parent2 = sortedPopulation[found2]\n",
    "            #print(\"parent2\", parent2)\n",
    "            #parent1 und parent2 sind die selektierten Individuen\n",
    "            #################################################################\n",
    "            \n",
    "            #Kreuzung########################################################\n",
    "            crossrn = np.random.rand()\n",
    "            if crossrn < kreuzPopulation:#wenn Wert innerhalb der Kreuzwahrscheinlichkeit gewürfelt -> kreuze\n",
    "                \n",
    "                #berechne random Index bei dem gekreuzt wird\n",
    "                crossIndex = np.random.randint(0, anzahlMerkmale-1)\n",
    "                \n",
    "                head1, tail = np.split(parent1, [crossIndex])\n",
    "                head2, tail = np.split(parent2, [crossIndex])\n",
    "                \n",
    "                # tail\n",
    "                tailind = 0\n",
    "                taillength1 = anzahlMerkmale - len(head1)\n",
    "                tail1 = np.zeros(taillength1, dtype=int)\n",
    "                \n",
    "                for i in range(0, anzahlMerkmale):\n",
    "                    if parent2[i] not in head1 and tailind < taillength1:\n",
    "                        tail1[tailind] = parent2[i]\n",
    "                        tailind = tailind + 1\n",
    "                \n",
    "                tailind = 0\n",
    "                taillength2 = anzahlMerkmale - len(head2)\n",
    "                tail2 = np.zeros(taillength2, dtype=int)\n",
    "                for j in range(0, anzahlMerkmale):\n",
    "                    if parent2[j] not in head2 and tailind < taillength2:\n",
    "                        tail2[tailind] = parent2[j]\n",
    "                        tailind = tailind + 1\n",
    "                \n",
    "                #Kind1 bekommt linken Teil von Parent1 und rechten Teil von Parent2\n",
    "                child1 = np.append(head1, tail1)\n",
    "                #Kind2 bekommt linken Teil von Parent2 und rechten Teil von Parent1\n",
    "                child2 = np.append(head2, tail2)\n",
    "            \n",
    "                #print(\"Kind1:\", child1)\n",
    "                #print(\"Kind2:\", child2)\n",
    "            #################################################################\n",
    "            \n",
    "            #Mutation########################################################\n",
    "            \n",
    "            #Fall child1\n",
    "            mutiere = np.random.rand() < mutationPopulation\n",
    "            #mutiere = True #SPÄTER AUSKOMMENTIEREN!!!!!!!!!!!!!!!\n",
    "            if mutiere:#wenn Wert innerhalb der Mutationswahrscheinlichkeit gewürfelt -> mutiere\n",
    "                #print(\"child1 mutiert\")\n",
    "                #Verändere ein Merkmal des Kindes. Dabei wird das aktuelle Merkmal mit einem zufälligen Merkmal aus FeatNames\n",
    "                #ausgetauscht. Das neue Merkmal soll noch nicht im Kind bereits vorkommen\n",
    "                neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #print(\"neues Merkmal:\", neuesMerkmal)\n",
    "                while neuesMerkmal in child1:\n",
    "                    #Wenn neues Merkmal bereits im Kind enthalten, würfele neu\n",
    "                    neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #wähle ein zufälliges Merkmal des Kindes aus was ersetzt wird\n",
    "                altesMerkmalPos = np.ceil(np.random.rand()*anzahlMerkmale).astype(int)-1\n",
    "                #print(\"Position altes Merkmal:\", altesMerkmalPos)\n",
    "                child1[altesMerkmalPos] = neuesMerkmal #ersetze Merkmal\n",
    "                #print(\"mutiertes child1:\", child1)\n",
    "            \n",
    "            #Fall child2\n",
    "            mutiere = np.random.rand() < mutationPopulation\n",
    "            #mutiere = True #SPÄTER AUSKOMMENTIEREN!!!!!!!!!!!!!!!\n",
    "            if mutiere:#wenn Wert innerhalb der Mutationswahrscheinlichkeit gewürfelt -> mutiere\n",
    "                #print(\"child2 mutiert\")\n",
    "                #Verändere ein Merkmal des Kindes. Dabei wird das aktuelle Merkmal mit einem zufälligen Merkmal aus FeatNames\n",
    "                #ausgetauscht. Das neue Merkmal soll noch nicht im Kind bereits vorkommen\n",
    "                neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #print(\"neues Merkmal:\", neuesMerkmal)\n",
    "                while neuesMerkmal in child2:\n",
    "                    #Wenn neues Merkmal bereits im Kind enthalten, würfele neu\n",
    "                    neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #wähle ein zufälliges Merkmal des Kindes aus was ersetzt wird\n",
    "                altesMerkmalPos = np.ceil(np.random.rand()*anzahlMerkmale).astype(int)-1\n",
    "                #print(\"Position altes Merkmal:\", altesMerkmalPos)\n",
    "                child2[altesMerkmalPos] = neuesMerkmal #ersetze Merkmal\n",
    "                #print(\"mutiertes child2:\", child2)\n",
    "            \n",
    "            #child1 und child2 sind die Resultate der Mutation #######################\n",
    "            \n",
    "            #Ersetze die schlechtesten zwei Individuen mit den Kindern, falls die Neuen besser sind#########\n",
    "            merkmaleChild1 = featureNames_fit[child1]\n",
    "            #print(\"merkmaleChild1\", merkmaleChild1)\n",
    "            df1_child1 = df_train_features[merkmaleChild1]\n",
    "            df2_child1 = df_test_features[merkmaleChild1]\n",
    "            midRank_child1 = mid_rank(df1_child1,df2_child1, fastEuclidean)\n",
    "            \n",
    "            merkmaleChild2 = featureNames_fit[child2]\n",
    "            #print(\"merkmaleChild2\", merkmaleChild2)\n",
    "            df1_child2 = df_test_features[merkmaleChild2]\n",
    "            df2_child2 = df_train_features[merkmaleChild2]\n",
    "            midRank_child2 = mid_rank(df1_child2,df2_child2, fastEuclidean)\n",
    "            \n",
    "            replace1=False\n",
    "            replace2=False\n",
    "            index = popSize -1\n",
    "            while index > 0:\n",
    "                if sortedDist[index]>midRank_child1 and not replace1:\n",
    "                    if not np.ndarray.any(np.ndarray.all(child1==sortedPopulation, axis=1)):\n",
    "                        sortedPopulation[index]= child1\n",
    "                    replace1=True\n",
    "                elif sortedDist[index]>midRank_child2 and not replace2:\n",
    "                    if not np.ndarray.any(np.ndarray.all(child2==sortedPopulation, axis=1)):\n",
    "                        sortedPopulation[index]= child2\n",
    "                    replace2=True\n",
    "                if replace1 and replace2:\n",
    "                    break\n",
    "                index=index-1\n",
    "            population=sortedPopulation\n",
    "            #print(\"Population am Ende der Iteration:\", population)\n",
    "            #print(\"bestDist:\", bestDist)\n",
    "            \n",
    "    #Graphische Anzeige#########################################\n",
    "    bestIndividuum = featureNames_fit[population[0]]\n",
    "    print(\"bestIndividuum \",bestIndividuum)\n",
    "    subFeaturesTrain1DF = df1[bestIndividuum]\n",
    "    subFeaturesTrain1DF.to_csv('./subFeaturesTrain1.csv', sep=\",\")\n",
    "    print(\"Best mid rank:\", bestDist[-1])\n",
    "    print(\"Population \", population[0])\n",
    "    plt.subplot(122)\n",
    "    plt.grid(True)\n",
    "    plt.plot(range(iterations), bestDist, label=label)\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "    return bestDist[-1]\n",
    "    ############################################################\n",
    "\n",
    "#genAlg(100, 100, 10, 0.1,'test') #iterationen, populationsize, #merkmale, mutationsRate, plotlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merkmal_10=genAlg(2000, 50, 10, 0.05, \"10 Merkmale\")\n",
    "print(\"Distanz bei 10 Merkmalen: \", Merkmal_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Music Feature Selection\n",
    "2. Implementieren und beschreiben Sie kurz das Konzept ihrer Kreuzungs- und Mutationsfunktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bestimmen Sie eine möglichst kleine Merkmalsuntermenge mit einem möglichst guten mittleren Rang? Geben Sie sowohl die gefundenen wichtigsten Merkmale als auch den zugehörigen mittleren Rang an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 20):\n",
    "    Merkmal_11=genAlg(2000, 50, 11, 0.05 , \"{0} Merkmale\".format(i))\n",
    "    print(\"Distanz bei {0} Merkmalen: \", \"Merkmale_{0}\".format(i, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Um wieviel verschlechtert sich der Mittlere Rang, wenn nur die 10 wichtigsten Merkmale benutzt werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering und automatische Playlistgenerierung\n",
    "Implementieren Sie ein hierarchisches Clustering aller Subsequenzen in _subFeaturesTrain1.csv_. Diese _.csv_-Datei enthält nur die im vorigen Schritt ermittelten wichtigsten Merkmale. Das hierarchische Clustering ist in einem Dendrogram der Art wie in der unten gegebenen Abbildung zu visualisieren.\n",
    "\n",
    "Die gefundenen Cluster sind mit den zugehörigen Musiktiteln in der Konsole auszugeben. \n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Optimieren Sie die Parameter\n",
    "\n",
    "    1. metric (Ähnlichkeitsmaß)\n",
    "    2. linkage method\n",
    "    3. Clusteranzahl\n",
    "    \n",
    "2. Für welche Parameterkonstellation erlangen Sie das für Sie subjektiv betrachtet günstigste Ergebnis?\n",
    "3. Überlegen Sie sich Ansätze um diese Art der Musikgruppierung zu verbessern?\n",
    "\n",
    "![Abbildung Music Clustering](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/playlistCluster.png \"Music Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
