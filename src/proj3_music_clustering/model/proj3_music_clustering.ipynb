{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Music Clustering\n",
    "* Prof: Dr. Johannes Maucher\n",
    "* Autor: Janina Mattes\n",
    "* Datum: 02.06.2020\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Musikdateien\n",
    "* Transcodierung von mp3 zu wav \n",
    "* Extraktion von Merkmalen in Musikdateien (Feature Extraction)\n",
    "* Optimierung mit dem genetischen Algorithmus\n",
    "* Selektion der aussagekräftigsten Merkmale (Feature Selection)\n",
    "* Clustering von Musikfiles (automatische Playlistgenerierung)\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "### Transcodierung von MP3 nach WAV und Merkmalsextraktion\n",
    "In diesem Versuch wird der MP3 Decoder [mpg123](http://www.mpg123.de/) eingesetzt. Installieren und testen sie diesen Decoder vor dem Versuch auf ihrem Rechner. Machen Sie sich zunächst mit dem in Kapitel [Gegebene Module zur Transcodierung und Feature Extraction](#Gegebene-Module-zur-Transcodierung-und-Feature-Extraction) aufgeführten Code vertraut. Versuchen Sie Funktion und Ablauf dieses Programms zu verstehen und beantworten Sie folgende Fragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Was versteht man unter den statistischen Größen _Mittelwert, Standardabweichung, Skewness und Kurtosis_?\n",
    "\n",
    "#### Mittelwert\n",
    "Mit dem Begriff Mittelwert (_auch Durchschnitt genannt_) ist in der Statistik meistens das _artithmetische Mittel_ gemeint. Der Mittelwert ist dabei eine Kennzahl für die zentrale Tendenz einer Verteilung. Das arithmetische Mittel ist rechnerisch die Summe der gegebenen Werte geteilt durch die Anzahl der Werte. Angewandt kann dies beispielsweise zum Berechnen einer Durchschnittsgeschwindigkeit werden. In diesem Fall würden die Werte als Geschwindigkeit interpretiert werden. Der _Erwartungswert_ einer Zufallsvariablen beschreibt hingegen die Zahl, die die Zufallsvariable im Mittel annimmt. \n",
    "\n",
    "#### Standardabweichung \n",
    "Die Standardabweichung ist ein Maß dafür, wie weit einzelne Datensätze verteilt sind. Mathematisch wird die Standardabweichung definiert als die mittlere quadratische Abweichung einer reellen Zufallsvariablen von ihrem Erwartungswert. Wenn alle Werte gleich sind, so ist die Standardabweichung Null, da diese von der Varianz abgeleitet ist. Das heißt je weiter Daten vertreut sind, desto höher ist die Standardabweichung. Je enger/näher Datensätze jedoch beieinander liegen, desto niedriger fällt die Standardabweichung aus. Es gibt zwei verschiedene Formeln der Anwendung, welche sich darin unterscheiden, dass nicht durch _n_, sondern durch _n-1_ geteilt wird.\n",
    "- die Standardabweichung für eine Stichprobe, wenn die Ergebnisse generalisierbar sein sollen. D.h. man möchte Ergebnisse erzielen, die es ermöglichen auf alle Menschen und nicht nur auf die ursprügnliche Versuchsgruppe _x_ Rückschlüsse zu ziehen.\n",
    "- die Standardabweichung für die Grundgesamtheit, wenn die Ergebnisse nicht verallgemeinert werden sollen. D.h. die Ergebnisse gelten nur für die Versuchsgruppe _x_.\n",
    "\n",
    "#### Skewness\n",
    "Die Maßzahl der Schiefe (_eng. skewness_) gibt an, inwieweit eine Verteilungsfunktion sich zu einer Seite \"neigt\". Das heißt diese ist ein Maß für die Asymmetrie einer Verteilung. Der Wert kann dabei _positiv_ (Verteilungsfunktion tendiert nach rechts), _negativ_ (Verteilungsfunktion tendiert nach links), _null_ (Verteilungsfunktion ist symmetrisch) und _undefiniert_ (0/0) sein.\n",
    "\n",
    "###### Eigenschaften einer unimodalen Verteilung**\n",
    "- linksschief (identisch mit dem Begriff rechtssteil) Verteilungen ist der Median größer als das arithmetische Mittel. \n",
    "- rechtsschief  (identisch mit dem Begriff linkssteil) Verteilungen ist der Modus kleiner als der Erwartungswert\n",
    "- Ist die Verteilungsfunktion symmetrisch, so ist das arithmetische Mittel gleich dem Median und die Verteilung wird eine Schiefe von 0 haben. \n",
    "\n",
    "#### Kurtosis\n",
    "Die Kurtosis (_dt. Wölbung_) ist ein Maß für die Steilheit einer Wahrscheinlichkeitsfunktion, oder Häufigkeitsverteilung. Verteilungen mit geringer Wölbung streuen relativ gleichmäßig. Bei Verteilungen mit hoher Wölbung resultiert die Streuung dagegen deutlich mehr aus extremen, aber seltenen Ereignissen. Der Exzess gibt die Differenz der Wölbung der betrachteten Funktion zur Wölbung der Dichtefunktion einer normalverteilten Zufallsgröße an. Jede nicht-symmetrische Verteilungsfunktion ist schief. Verteilungen mit niederger Kurtosis streuen relativ gleichmäßig(breite Glocke), Verteilungen mit hoher Kurtosis haben eine mehr extreme auf einem Punkt verteilte Streuung(spitze Glocke)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Was beschreibt die Fourier-Transformierte eines zeitlich ausgedehnten Signals?\n",
    "\n",
    "#### Die Fourier Transformation\n",
    "Die Fourier-Transformation (genauer die kontinuierliche Fourier-Transformation  ist eine mathematische Methode aus dem Bereich der Fourier-Analysis, mit der kontinuierliche, aperiodische Signale in ein kontinuierliches Spektrum zerlegt werden. Die Funktion, die dieses Spektrum beschreibt, nennt man auch Fourier-Transformierte oder Spektralfunktion. Es handelt sich dabei um eine Integraltransformation, die nach dem Mathematiker Jean Baptiste Joseph Fourier benannt ist. Fourier führte im Jahr 1822 die Fourier-Reihe ein, die jedoch nur für periodische Signale definiert ist und zu einem diskreten Frequenzspektrum führt. Die Entwicklung einer Funktion in ihre _Fourier-Reihe_ wird harmonische Analyse genannt. Die Funktion wird dabei als Überlagerung von sinusförmigen, Schwingungen dargestellt. Ist die Funktion ein Eingangssignal eines LTI-Systems, kann das Ausgangssignal relativ einfach berechnet werden, da das Signals als Überlagerung von Eigenfunktionen des Systems vorliegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Mit welcher Samplingrate werden die WAV Dateien abgetastet?\n",
    "\n",
    "#### Abtastrate von WAV Dateien\n",
    "Die Abtastrate oder Abtastfrequenz, auch Samplingrate, Samplerate oder Samplingfrequenz, ist in der Signalverarbeitung die Häufigkeit, mit der ein Analogsignal (auch zeitkontinuierliches Signal genannt) in einer vorgegebenen Zeit abgetastet (das heißt, gemessen und in ein zeitdiskretes Signal umgewandelt) wird. Da es sich bei einer Abtastung immer um einen periodischen Vorgang handelt, ist ihre grundlegende Einheit das *Hertz* (abgekürzt: Hz), also Perioden pro Sekunde. \n",
    "- Ein Abtastvorgang pro Sekunde: 1 Hz = 1 S/s\n",
    "\n",
    "Die Waveform Audi File Format (_WAV_) ist eine von IBM und Missrn\n",
    "soft entwickeltes Containerformat für die Speicherung von Audiodaten. Die in den Containern enthaltenen  Dateien sind normalerweise unkomprimierte in _Pulscodemodulation (PCM)_ codierte Audiosignale für die Speicherung und Bearbeitung von Audio-Informationen. WAV-Dateien sind unkomprimiert und fehlerfrei, aber relativ groß. Ihre Größe ergibt sich aus der Abtastrate und der Samplingtiefe bei der Digitalisierung des analogen Audiosignals. Daraus ergibt sich bei einer standardmäßigen Abtastrate von **44,1 kHz** und einer Samplingtiefe von **16 Bit** eine Dateigröße von **5,3 Megabyte (MB) pro Minute** für ein Monosignal. Es sind allerdings auch andere Abtastraten und Sampletiefen möglich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Insgesamt werden 42 Merkmale pro Musiksequenz extrahiert. Beschreiben Sie kurz diese Merkmale\n",
    "\n",
    "#### Merkmalsextraktion bei WAV Dateien\n",
    "Die extrahierten Merkmale betreffen die Kurtuosis, ... Diese Merkmale liegen sowohl im Spektralbereich, als auch Merkmale im Zeitbereich.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching der Teilsequenzen\n",
    "\n",
    "1. Nachdem für jedes Musikstück die beiden Teilsequenzen in Form der extrahierten Merkmale vorliegen: Wie kann die Ähnlichkeit zwischen Teilsequenzen ermittelt \n",
    "werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Die Musikstücke, welche als Trainingsdaten vorliegen, werden die einzelnen Teilsequencen in Vektoren umgewandelt und anschließend auf deren Ähnlichkeit miteinander vergliechen. Haben diese eine hohe Ähnlichkeit, so so müsste das erste Teilstück und das zweite Teilstück gleich oder sehr ähnlich sein. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Welche Numpy- bzw. Scipy-Module können Sie für die Bestimmung der Ähnlichkeit zwischen Teilsequenzen einsetzen?\n",
    "\n",
    "Aus der Scipy Libary können folgende Funktionen angewandt werden, um die Ähnlichkeit der einzelnen Teilsequenzen zu berechnen.  \n",
    "\n",
    "```\n",
    "scipy.spatial.distance.euclidean (Euklid)\n",
    "\n",
    "scipy.stats.pearsonr (Pearson)\n",
    "\n",
    "scipy.spatial.distance.cosine (Kosinus)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetischer Algorithmus für die Merkmalsselektion\n",
    "\n",
    "1. Beschreiben Sie die Prozesschritte im genetischen Algorithmus [Genetischer Algorithmus](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html)\n",
    "\n",
    "#### Der Genetische Algorithmus\n",
    "Ein Genetischer Algorithmus (GA) ist eine Such-Heuristik, welche durch _Charls Darwin's_ Theorie der natürlichen Evolution inspiriert wurde. Dieser reflektiert den Prozess, in welchem eine natürliche Selektion der besten (_fittest_) Individuen einer Population für eine Reproduktion selektiert werden. Genetische Algorithmen (GA) sind sehr gut für Probleme in der Suche, als auch für Optimierungen einzusetzen. Ein Beispiel hierfür ist der Einsatz eines _GA_, um eine Lösung für das \"Travelling Salesman Problem\" (TSP) zu finden. \n",
    "Für die Erkundung der besten Merkmale in diesem Fall werden die einzelnen Elemente des GA auf die Problemstellung wie folgt übertragen: \n",
    "\n",
    "\n",
    "* **Gene**: Satz an Parametern (Variablen).\n",
    "* **Individual/Chromosome**: Ein Chromosom ist eine Zusammensetzung von Genen. In diesem Fall ein einzelnes Merkmal, welches die Bedingungen erfüllt. \n",
    "* **Population**: Eine Sammlung möglicher Merkmale.\n",
    "* **Parents**: Zwei Merkmale, welche kombiniert werden, um ein neues Merkmal zu generieren.\n",
    "* **Mating Pool**: Eine Sammlung an Elternteilen, welche dazu verwendet werden, eine neue Population (nächste Generation) zu generieren.\n",
    "* **Fitness**: Eine Funktion, welche die Güte der Mermale anhand ihres _mittleren Rangs_ bewertet.\n",
    "* **Mutation**: Eine Möglichkeit Variationen in der Population zu erzeugen, durch zufälliges austauschen von Elementen der Merkmale.\n",
    "\n",
    "#### Schritte der Ausführung\n",
    "\n",
    "##### Erzeugung zufälliger Population:\n",
    "Erzeugt eine Menge von Individuen mit zufälligen Chromosomen. Jedes Individum ist ein Lösungsvorschlag für ein Problem.\n",
    "\n",
    "##### Bestimme Fitness:\n",
    "Individuen werden anhand einer Fitnessfunktion bewertet.\n",
    "\n",
    "##### Selektion:\n",
    "Wähle ein Paar von Individuen aus. Die Auswahl ist von der Fitness abhängig. Je höher die Fitness, desto höher die Wahrscheinlichkeit, dass sie für die Kreuzung ausgewählt werden.\n",
    "\n",
    "##### Kreuzung:\n",
    "\n",
    "Paare werden gekreuzt und erzeugen Nachkommen, welche die Chromosomen der Eltern erben. Hier wird ein zufälliger Schnittpunkt zur Vereinigung der Elternvektoren genutzt. Die Chromosome werden an dieser Stelle geteilt und miteinander vertauscht.\n",
    "\n",
    "##### Mutation:\n",
    "\n",
    "Ein Teil der Chromosomen wird zufällig verändert. Es gibt eine Mutationswahrscheinlichkeit, folglich kommt es nicht immer zu einer Mutation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In diesem Versuch wird davon ausgegangen, dass Merkmale dann gut sind, wenn durch sie die erste Teilsequenz eines Musikstücks durch einen ähnlichen Vektor wie die jeweils zweite Teilsequenz beschrieben wird. Wie kann mit dieser Annahme der genetische Algorithmus für die Merkmalsselektion angewandt werden. Unter Merkmalsselektion versteht man allgemein die Suche nach den $r$ besten Merkmalen aus einer Menge von insgesamt $R$ Merkmalen. In diesem Versuch werden initial $R=42$ Merkmale extrahiert, aus denen dann die besten $r<R$ Merkmale zu bestimmen sind. Überlegen Sie hierfür speziell wie die Fitnessfunktion, die Kreuzung und die Mutation zu realisieren sind.\n",
    "\n",
    "##### Fitnessfunktion:\n",
    "\n",
    "Euklidische Distanz der verwendeten Features zwischen der ersten und der zweiten Teilsequenz. Diese errechneten Werte werden aufsteigend sortiert in einem Array abgespeichert. Danach wird aus dem Array ein Mittlerer Rang(siehe Aufgabebeschreibung Matching der Teilsequenzen 4.) berechnet. Dieser spiegelt die Fitness wieder.\n",
    "\n",
    "##### Kreuzung:\n",
    "\n",
    "Indivduen mit niedriger Distanz bzw. mit gutem Fitnesswert werden miteinander gekreuzt. Dabei wird ein zufälliger Schnittpunkt zur Vereinigung der Elternvektoren genutzt. Die Chromosome werden an dieser Stelle geteilt und miteinander vertauscht.\n",
    "\n",
    "##### Mutation:\n",
    "\n",
    "Mit niedriger Wahrscheinlichkeit wird ein Wert zufällig verändert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering und Playlistgenerierung\n",
    "\n",
    "1. Wie kann mit einem hierarchischen Clustering der Musikfiles eine Menge von Playlists erzeugt werden, so dass innerhalb einer Playlist möglichst ähnliche Titel zu finden sind?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Gegebene Module zur Transcodierung und Feature Extraction\n",
    "Mit dem in diesem Abschnitt gegebenen Code werden die im Unterverzeichnis _BandCollection_ befindlichen mp3-Files zunächst in wave decodiert. Danach werden aus den wave Dateien Audiomerkmale erhoben.\n",
    "\n",
    "Von jedem Musikstück werden zwei disjunkte Teilsequenzen erhoben und von beiden Teilsequenzen jeweils ein Merkmalsvektor gebildet. Der Grund hierfür ist: Für die später folgende Bestimmung der wichtigsten Merkmale (Merkmalsselektion mit dem genetischen Algorithmus), wird angenommen dass Merkmale dann gut sind, wenn die aus ihnen gebildeten Merkmalsvektoren für Teilsequenzen des gleichen Musikstücks nahe beieinander liegen und die Merkmalsvektoren von Teilsequenzen unterschiedlicher Musikstücke weiter voneinander entfernt sind. In der Merkmalsselektion werden dann die Merkmale als relevant erachtet, für die diese Annahme zutrifft. \n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Stellen Sie im unten gegebenen Code die Verzeichnisse für Ihre Musikdateien (aktuell Unterverzeichnis _BandCollection_) und für den Ort Ihres _mpg123_ Decoders richtig ein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPG123_PATH = 'C:\\Program Files (x86)\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "MUSIC_FILE_PATH = '../data/BandCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Wave\n",
    "#!pip install pandas\n",
    "\n",
    "import subprocess\n",
    "import wave\n",
    "import struct\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(precision=2,suppress=True)\n",
    "\n",
    "#Names of features extracted in this module\n",
    "FeatNames=[\"amp1mean\",\"amp1std\",\"amp1skew\",\"amp1kurt\",\"amp1dmean\",\"amp1dstd\",\"amp1dskew\",\"amp1dkurt\",\"amp10mean\",\"amp10std\",\n",
    "           \"amp10skew\",\"amp10kurt\",\"amp10dmean\",\"amp10dstd\",\"amp10dskew\",\"amp10dkurt\",\"amp100mean\",\"amp100std\",\"amp100skew\",\n",
    "           \"amp100kurt\",\"amp100dmean\",\"amp100dstd\",\"amp100dskew\",\"amp100dkurt\",\"amp1000mean\",\"amp1000std\",\"amp1000skew\",\n",
    "           \"amp1000kurt\",\"amp1000dmean\",\"amp1000dstd\",\"amp1000dskew\",\"amp1000dkurt\",\"power1\",\"power2\",\"power3\",\"power4\",\n",
    "           \"power5\",\"power6\",\"power7\",\"power8\",\"power9\",\"power10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments(x):\n",
    "    mean = x.mean()\n",
    "    std = x.var()**0.5\n",
    "    skewness = ((x - mean)**3).mean() / std**3\n",
    "    kurtosis = ((x - mean)**4).mean() / std**4\n",
    "    return [mean, std, skewness, kurtosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature category 2: Frequency domain parameters\n",
    "def fftfeatures(wavdata):\n",
    "    f = numpy.fft.fft(wavdata)\n",
    "    f = f[2:int(f.size / 2 + 1)]\n",
    "    f = abs(f)\n",
    "    total_power = f.sum()\n",
    "    f = numpy.array_split(f, 10)\n",
    "    return [e.sum() / total_power for e in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the entire feature vector per music-file\n",
    "def features(x):\n",
    "    x = numpy.array(x)\n",
    "    f = []\n",
    "\n",
    "    xs = x\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 10).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 100).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 1000).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    f.extend(fftfeatures(x))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Die verwendete Musiksammlung sollte mindestens 5 verschiedene Interpreten möglichst unterschiedlicher Genres enthalten. Von jedem Interpret sollten mehrere Titel (evtl. ein ganzes Album) enthalten sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(wav_file):\n",
    "    \"\"\"Returns two chunks of sound data from wave file.\"\"\"\n",
    "    w = wave.open(wav_file)\n",
    "    n = 60 * 10000\n",
    "    if w.getnframes() < n * 3:\n",
    "        raise ValueError('Wave file too short')\n",
    "    #For each music file 2 sequences, each containing n frames are subtracted. The first sequence starts at postion n,\n",
    "    #the second sequence starts at postion 2n. The reason for extracting 2 subsequences is, that later on we like to\n",
    "    #find the best features and in this exercise we assume that good features have the property that they are similar for 2 subsequences\n",
    "    #of the same song, but differ for subsequences of different songs.\n",
    "    w.setpos(n)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data1 = struct.unpack('%dh' % n, frames)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data2 = struct.unpack('%dh' % n, frames)\n",
    "    return wav_data1, wav_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chunk_features(mp3_file):\n",
    "    \"\"\"Return feature vectors for two chunks of an MP3 file.\"\"\"\n",
    "    # Extract MP3 file to a mono, 10kHz WAV file\n",
    "    #mpg123_command = 'C:\\Program Files (x86)\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    #mpg123_command = 'C:\\\\Program Files (x86)\\\\mpg123-1.24.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    mpg123_command = MPG123_PATH\n",
    "    out_file = 'temp.wav'\n",
    "    cmd = mpg123_command % (out_file, mp3_file)\n",
    "    temp = subprocess.call(cmd)\n",
    "    # Read in chunks of data from WAV file\n",
    "    wav_data1, wav_data2 = read_wav(out_file)\n",
    "    # We'll cover how the features are computed in the next section!\n",
    "    return numpy.array(features(wav_data1)), numpy.array(features(wav_data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Führen Sie den in diesem Abschnitt gegebenen Programmcode zur Audiofeature-Extraction aus. Damit werden für alle Musiksequenzen jeweils 42 Merkmale extrahiert. Die extrahierten Merkmalsvektoren der jeweils ersten Sequenz werden in das File _FeatureFileTrainingAllList1.csv_ geschrieben, die der zweiten Teilsequen in das File _FeatureFileTestAllList2.csv_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/BandCollection\\Adele\\01 Hometown Glory.mp3\n",
      "--------------------Adele\\01 Hometown Glory.mp3--------------------\n",
      "../data/BandCollection\\Adele\\02 I'll Be Waiting.mp3\n",
      "--------------------Adele\\02 I'll Be Waiting.mp3--------------------\n",
      "../data/BandCollection\\Adele\\03 Don't You Remember.mp3\n",
      "--------------------Adele\\03 Don't You Remember.mp3--------------------\n",
      "../data/BandCollection\\Adele\\04 Turning Tables.mp3\n",
      "--------------------Adele\\04 Turning Tables.mp3--------------------\n",
      "../data/BandCollection\\Adele\\05 Set Fire To The Rain.mp3\n",
      "--------------------Adele\\05 Set Fire To The Rain.mp3--------------------\n",
      "../data/BandCollection\\Adele\\06 If It Hadn't Been For Love.mp3\n",
      "--------------------Adele\\06 If It Hadn't Been For Love.mp3--------------------\n",
      "../data/BandCollection\\Adele\\07 My Same.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Adele\\08 Take It All.mp3\n",
      "--------------------Adele\\08 Take It All.mp3--------------------\n",
      "../data/BandCollection\\Adele\\09 Rumour Has It.mp3\n",
      "--------------------Adele\\09 Rumour Has It.mp3--------------------\n",
      "../data/BandCollection\\Adele\\10 Right As Rain.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Adele\\11 One And Only.mp3\n",
      "--------------------Adele\\11 One And Only.mp3--------------------\n",
      "../data/BandCollection\\Adele\\12 Lovesong.mp3\n",
      "--------------------Adele\\12 Lovesong.mp3--------------------\n",
      "../data/BandCollection\\Adele\\13 Chasing Pavements.mp3\n",
      "--------------------Adele\\13 Chasing Pavements.mp3--------------------\n",
      "../data/BandCollection\\Adele\\14 I Can't Make You Love Me.mp3\n",
      "--------------------Adele\\14 I Can't Make You Love Me.mp3--------------------\n",
      "../data/BandCollection\\Adele\\15 Make You Feel My Love.mp3\n",
      "--------------------Adele\\15 Make You Feel My Love.mp3--------------------\n",
      "../data/BandCollection\\Adele\\16 Someone Like You.mp3\n",
      "--------------------Adele\\16 Someone Like You.mp3--------------------\n",
      "../data/BandCollection\\Adele\\17 Rolling In The Deep.mp3\n",
      "--------------------Adele\\17 Rolling In The Deep.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\01 So What'cha Want.mp3\n",
      "--------------------BeastieBoys\\01 So What'cha Want.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\02 Brass Monkey.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\03 Ch-Check It Out.mp3\n",
      "--------------------BeastieBoys\\03 Ch-Check It Out.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\04 No Sleep Till Brooklyn.mp3\n",
      "--------------------BeastieBoys\\04 No Sleep Till Brooklyn.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\05 Hey Ladies.mp3\n",
      "--------------------BeastieBoys\\05 Hey Ladies.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\06 Pass the Mic.mp3\n",
      "--------------------BeastieBoys\\06 Pass the Mic.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\07 An Open Letter to NYC.mp3\n",
      "--------------------BeastieBoys\\07 An Open Letter to NYC.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\08 Root Down.mp3\n",
      "--------------------BeastieBoys\\08 Root Down.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\09 Shake Your Rump.mp3\n",
      "--------------------BeastieBoys\\09 Shake Your Rump.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\10 Intergalactic.mp3\n",
      "--------------------BeastieBoys\\10 Intergalactic.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\11 Sure Shot.mp3\n",
      "--------------------BeastieBoys\\11 Sure Shot.mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3\n",
      "--------------------BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3--------------------\n",
      "../data/BandCollection\\BeastieBoys\\13 Triple Trouble.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\14 Sabotage.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\BeastieBoys\\15 Fight for Your Right.mp3\n",
      "--------------------BeastieBoys\\15 Fight for Your Right.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\01 Smooth Criminal 1.mp3\n",
      "--------------------Garrett\\01 Smooth Criminal 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\02 Who Wants to Live Forever_ 1.mp3\n",
      "--------------------Garrett\\02 Who Wants to Live Forever_ 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\03 Clair de Lune 1.mp3\n",
      "--------------------Garrett\\03 Clair de Lune 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3\n",
      "--------------------Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\05 Summertime 1.mp3\n",
      "--------------------Garrett\\05 Summertime 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\06 Brahms Hungarian Dance No. 5 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\07 Chelsea Girl 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\08 Summer 1.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\09 O Mio Babbino Caro 1.mp3\n",
      "--------------------Garrett\\09 O Mio Babbino Caro 1.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\10 Air.mp3\n",
      "--------------------Garrett\\10 Air.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\11 Thunderstruck.mp3\n",
      "--------------------Garrett\\11 Thunderstruck.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\12 New Day.mp3\n",
      "--------------------Garrett\\12 New Day.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\13 Ain't No Sunshine.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\14 Rock Prelude.mp3\n",
      "--------------------Garrett\\14 Rock Prelude.mp3--------------------\n",
      "../data/BandCollection\\Garrett\\15 Winter Lullaby.mp3\n",
      "Error: Chunk Features failed\n",
      "../data/BandCollection\\Garrett\\16 Little Wing.mp3\n",
      "--------------------Garrett\\16 Little Wing.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\01 Born to Die.mp3\n",
      "--------------------LanaDelRey\\01 Born to Die.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\02 Off to the Races.mp3\n",
      "--------------------LanaDelRey\\02 Off to the Races.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\03 Blue Jeans (Remastered).mp3\n",
      "--------------------LanaDelRey\\03 Blue Jeans (Remastered).mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\04 Video Games (Remastered).mp3\n",
      "--------------------LanaDelRey\\04 Video Games (Remastered).mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\05 Diet Mountain Dew.mp3\n",
      "--------------------LanaDelRey\\05 Diet Mountain Dew.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\06 National Anthem.mp3\n",
      "--------------------LanaDelRey\\06 National Anthem.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\07 Dark Paradise.mp3\n",
      "--------------------LanaDelRey\\07 Dark Paradise.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\08 Radio.mp3\n",
      "--------------------LanaDelRey\\08 Radio.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\09 Carmen.mp3\n",
      "--------------------LanaDelRey\\09 Carmen.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\10 Million Dollar Man.mp3\n",
      "--------------------LanaDelRey\\10 Million Dollar Man.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\11 Summertime Sadness.mp3\n",
      "--------------------LanaDelRey\\11 Summertime Sadness.mp3--------------------\n",
      "../data/BandCollection\\LanaDelRey\\12 This Is What Makes Us Girls.mp3\n",
      "--------------------LanaDelRey\\12 This Is What Makes Us Girls.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\01 Bombtrack.mp3\n",
      "--------------------RageAgainstTheMachine\\01 Bombtrack.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\02 Killing In the Name.mp3\n",
      "--------------------RageAgainstTheMachine\\02 Killing In the Name.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\03 Take the Power Back.mp3\n",
      "--------------------RageAgainstTheMachine\\03 Take the Power Back.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\04 Settle for Nothing.mp3\n",
      "--------------------RageAgainstTheMachine\\04 Settle for Nothing.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\05 Bullet In the Head.mp3\n",
      "--------------------RageAgainstTheMachine\\05 Bullet In the Head.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\06 Know Your Enemy.mp3\n",
      "--------------------RageAgainstTheMachine\\06 Know Your Enemy.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\07 Wake Up.mp3\n",
      "--------------------RageAgainstTheMachine\\07 Wake Up.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\08 Fistful of Steel.mp3\n",
      "--------------------RageAgainstTheMachine\\08 Fistful of Steel.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\09 Township Rebellion.mp3\n",
      "--------------------RageAgainstTheMachine\\09 Township Rebellion.mp3--------------------\n",
      "../data/BandCollection\\RageAgainstTheMachine\\10 Freedom.mp3\n",
      "--------------------RageAgainstTheMachine\\10 Freedom.mp3--------------------\n"
     ]
    }
   ],
   "source": [
    "fileList=[]\n",
    "featureList1=[]\n",
    "featureList2=[]\n",
    "#Specify the name of the directory, which contains your MP3 files here.\n",
    "# This directory should contain for each band/author one subdirectory, which contains all songs of this author\n",
    "for path, dirs, files in os.walk(MUSIC_FILE_PATH):\n",
    "    #print '-'*10,dirs,files\n",
    "    for f in files:\n",
    "        if not f.endswith('.mp3'):\n",
    "            # Skip any non-MP3 files\n",
    "            continue\n",
    "        mp3_file = os.path.join(path, f)\n",
    "        print(mp3_file)\n",
    "        # Extract the track name (i.e. the file name) plus the names\n",
    "        # of the two preceding directories. This will be useful\n",
    "        # later for plotting.\n",
    "        tail, track = os.path.split(mp3_file)\n",
    "        tail, dir1 = os.path.split(tail)\n",
    "        tail, dir2 = os.path.split(tail)\n",
    "        # Compute features. feature_vec1 and feature_vec2 are lists of floating\n",
    "        # point numbers representing the statistical features we have extracted\n",
    "        # from the raw sound data.\n",
    "        try:\n",
    "            feature_vec1, feature_vec2 = compute_chunk_features(mp3_file)\n",
    "        except:\n",
    "            print(\"Error: Chunk Features failed\")\n",
    "            continue\n",
    "        #title=str(track)\n",
    "        title=str(dir1)+'\\\\'+str(track)\n",
    "        print('-'*20+ title +'-'*20) \n",
    "        #print \"       feature vector 1:\",feature_vec1\n",
    "        #print \"       feature vector 2:\",feature_vec2\n",
    "        fileList.append(title)\n",
    "        featureList1.append(feature_vec1)\n",
    "        featureList2.append(feature_vec2)\n",
    "\n",
    "# Write feature vecotrs of all music files to pandas data-frame\n",
    "MusicFeaturesTrain = pd.DataFrame(index=fileList, data=numpy.array(featureList1), columns=FeatNames)\n",
    "MusicFeaturesTrain.to_csv(\"FeatureFileTrainingAllList1.csv\")\n",
    "\n",
    "MusicFeaturesTest = pd.DataFrame(index=fileList, data=numpy.array(featureList2), columns=FeatNames)\n",
    "MusicFeaturesTest.to_csv(\"FeatureFileTestAllList2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching der Teilsequenzen\n",
    "In diesem Abschnitt soll ein Verfahren implementiert werden, mit dem die Übereinstimmung der ersten Teilsequenz eines Musikstücks mit den zweiten Teilsequenzen aller anderen Musikstücke berechnet werden kann.\n",
    "\n",
    "**Aufagben:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install prettyprint\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lesen Sie die im vorigen Teilversuch angelegten zwei csv-Dateien in jeweils einen eigenen Pandas Dataframe ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = pd.read_csv(\"FeatureFileTrainingAllList1.csv\", sep=\",\", header=0, names=FeatNames)\n",
    "df_test_features = pd.read_csv(\"FeatureFileTestAllList2.csv\", sep=\",\", header=0, names=FeatNames)\n",
    "#pp.pprint(df_train_features.head(5))\n",
    "#pp.pprint(df_test_features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Skalieren Sie beide Teilsequenzmengen, so dass alle Merkmale eine Standardabweichung von 1 aufweisen. Z.B. mit [http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn --upgrade\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.preprocessing.scale(X, *, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "# returns a numpy array\n",
    "train_features_scaled = preprocessing.scale(df_train_features)\n",
    "test_features_scaled = preprocessing.scale(df_test_features)\n",
    "\n",
    "##pp.pprint(train_features_scaled)\n",
    "##pp.pprint(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pp.pprint('Mean value \\n {0}'.format(train_features_scaled.mean(axis=0)))\n",
    "##pp.pprint('Standard deviation \\n {0}'.format(train_features_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pp.pprint('Mean value \\n {0}'.format(test_features_scaled.mean(axis=0)))\n",
    "##pp.pprint('Standard deviation \\n {0}'.format(test_features_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = pd.DataFrame(data=train_features_scaled, index=df_train_features.index, columns=df_train_features.columns)\n",
    "df_test_features = pd.DataFrame(data=test_features_scaled, index=df_test_features.index, columns=df_test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp.pprint('The train features Dataframe {}'.format(df_train_features))\n",
    "#pp.pprint('The test features Dataframe {}'.format(df_test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die merkmalsausprägung von Objekten unterliegt _Streuungen_. Hierdurch kann eine Distanz _d{ij} zwischen den Objekten durch die Mermale dominiert werden, die eine entsprechend große Streuung besitzen. Dieser Umstand ist besonders zu berücksichtigen, wenn zwischen den Objektmerkmalen, deutliche Größenunterschiede bestehen. Um die Streuung zu berücksichtigen, werden die Merkmale _skaliert_. Wird die Distanz über die _L-2_ Norm bestimmt, kann die Skalierung über die **Standardabweichung** _s_ durchgeführt werden. Dazu wird _F2_ um die quadratische Standardabweichung _s_ ergänzt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnung der skalierten Distanz\n",
    "**3.1 Euklidsche Distanz**: Bestimmen Sie zu jeder Teilsequenz aus der Datei _FeatureFileTrainingAllList1.csv_ die euklidische Distanz zu allen Teilsequenzen aus der Datei _FeatureFileTestAllList2.csv_ und schreiben Sie diese Distanzen in eine aufsteigend geordnete Liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euklidische Distanz zu allen Teilsequenzen\n",
    "def calcEuclideandDist(df_one, df_two):\n",
    "    euclid_dist_dict = {}\n",
    "    for index_one, row_one in df_one.iterrows():\n",
    "        euclid_dist_list = []\n",
    "        for index_two, row_two in df_two.iterrows():\n",
    "            euclid_dist_list.append([distance.euclidean(row_one, row_two), index_two])\n",
    "        euclid_dist_list.sort()\n",
    "        euclid_dist_dict[index_one] = euclid_dist_list\n",
    "    return euclid_dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "euclid_dist_dict = calcEuclideandDist(df_train_features, df_test_features)\n",
    "print(len(euclid_dist_dict))\n",
    "#pp.pprint(euclid_dist_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Korrelative Distanz**: Schreiben Sie auch die zugehörigen Argumente (Teilsequenzen) in eine geordnete Liste, sodass für jede Teilsequenz aus _FeatureFileTrainingAllList1.csv_ die am nächsten liegende Teilsequenz aus _FeatureFileTestAllList2.csv_ an erster Stelle steht, die zweitnächste Teilsequenz an zweiter usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zugehörige Argumente für beide Teilsequenzen\n",
    "def calcCorrelationDist(df_one, df_two):\n",
    "    cor_dist_dict={}\n",
    "    for index_one, row_one in df_one.iterrows():\n",
    "        cor_dist_list = []\n",
    "        for index_two, row_two in df_two.iterrows():\n",
    "            cor_dist_list.append([distance.correlation(row_one, row_two), index_two])\n",
    "        cor_dist_list.sort()\n",
    "        cor_dist_dict[index_one] = cor_dist_list\n",
    "    return cor_dist_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "cor_dist_dict = calcCorrelationDist(df_train_features, df_test_features)\n",
    "print(len(cor_dist_dict))\n",
    "#pp.pprint(cor_dist_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnung des Mittleren Rangs\n",
    "4. Bestimmen Sie über alle Teilsequenzen aus _FeatureFileTrainingAllList1.csv_ den **mittleren Rang** an dem die zugehörige zweite Teilsequenz erscheint. Liegt z.B. für die erste Teilsequenz des Musikstücks A die zweite Teilsequenz nur an fünfter Stelle der geordneten nächsten Nachbarliste. Dann würde diese Teilsequenz mit dem Rang 5 in den Mittelwert einfließen.\n",
    "\n",
    "Hinweis: Werden die verkürzten Files mit 50 anstelle von 60 genommen. Aufgrund dieser geänderten Datengrundlage sind die aktuellen Abweichungen vorhanden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanRank(dist_dict):\n",
    "    # initialize the dict\n",
    "    rank_list = []\n",
    "    for seq_one, seq_one_val in dist_dict.items():\n",
    "        for index, seq_two_val in enumerate(seq_one_val):\n",
    "            if seq_one == seq_two_val[1]:\n",
    "                rank_list.append(index + 1) # shift by one as rank zero isnt allowed\n",
    "    # calculate mean\n",
    "    mean_rank = mean(rank_list)\n",
    "    return mean_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.65"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_mean_rank = calcMeanRank(cor_dist_dict)\n",
    "cor_mean_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bestimmen Sie jetzt den mittleren Rang, für den Fall, dass _correlation_ anstelle _euclidean_ als Ähnlichkeitsmaß verwendet wird. Welches Ähnlichkeitsmaß ist für diese Anwendung zu bevorzugen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5166666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euc_mean_rank = calcMeanRank(euclid_dist_dict)\n",
    "euc_mean_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Diskutieren Sie das Ergebnis\n",
    "\n",
    "Der mittlere Rang bei der Berechnung mit dem Ähnlichkeitsmaß der _correlation_ ergibt einen Wert von 2.65, während die Berechnung mit dem Ähnlichkeitsmaß der _euclidean_ einen leicht besseren Wert von 2.65 ergibt. \n",
    "\n",
    "Daher wäre das euklidsche Ähnlichkeitsmaß hier zu bevorzugen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die euklidische Distanz wird auch _L2-Norm_ genannt und ist eine Variante der sogenannten Minkowski-Metrik zur Berechnung von distanzen zwischen Vektoren (Punkte) in einem höherdimensionalen Raum. Die Korrelation ist ein Maß für den statistischen Zusammenhang zwischen zwei Datensätzen. Der mittlere Rang bei der Berechnung mit dem Ähnlichkeitsmaß der _correlation_ ergibt einen Wert von 2.65, während die Berechnung mit dem Ähnlichkeitsmaß der _euclidean_ einen leicht besseren Wert von 2.65 ergibt. Das Ähnlichkeitsmaß von Euklid ist in diesem Fall für die Anwendung zu bevorzugen, da dies eine bessere Aussage über die tatsächliche Ähnlichkeit der Formen zwischen den Vektoren erlaubt. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis zu anderen Bereichen: In der Signalverarbeitung wird häufig die Metrik der _Korrelation_ oder _Cross-Correlation_ eingesetzt. Dabei ist ein Wert größer als 0.8 anzustreben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalsauswahl mit dem genetischen Algorithmus\n",
    "In diesem Abschnitt soll unter Anwendung eines selbst zu implementierenden genetischen Algorithmus eine Untermenge wichtiger Merkmale aus den insgesamt 42 angelegten Merkmalen berechnet werden.\n",
    "Als Vorlage kann hierfür die Implementierung für die [Lösung des TSP Problems](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html) herangezogen werden. Anzupassen sind dann jedoch mindestens die Fitness-Funktion, die Kreuzungs- und die Mutationsfunktion. \n",
    "\n",
    "#### Der Genetische Algorithmus\n",
    "Ein Genetischer Algorithmus (GA) ist eine Such-Heuristik, welche durch _Charls Darwin's_ Theorie der natürlichen Evolution inspiriert wurde. Dieser reflektiert den Prozess, in welchem eine natürliche Selektion der besten (_fittest_) Individuen einer Population für eine Reproduktion selektiert werden. Genetische Algorithmen (GA) sind sehr gut für Probleme in der Suche, als auch für Optimierungen einzusetzen. Ein Beispiel hierfür ist der Einsatz eines _GA_, um eine Lösung für das \"Travelling Salesman Problem\" (TSP) zu finden. \n",
    "Für die Erkundung der besten Merkmale in diesem Fall werden die einzelnen Elemente des GA auf die Problemstellung wie folgt übertragen: \n",
    "\n",
    "* **Gene**: Einzelnes Element eines Merkmals, bzw. ein Satz an Parametern (Variablen).\n",
    "* **Individual/Chromosome**: Ein Chromosom ist eine Zusammensetzung von Genen. In diesem Fall ein einzelnes Merkmal, welches die Bedingungen erfüllt. \n",
    "* **Population**: Eine Sammlung möglicher Merkmale.\n",
    "* **Parents**: Zwei Merkmale, welche kombiniert werden, um ein neues Merkmal zu generieren.\n",
    "* **Mating Pool**: Eine Sammlung an Elternteilen, welche dazu verwendet werden, eine neue Population (nächste Generation) zu generieren.\n",
    "* **Fitness**: Eine Funktion, welche die Güte der Mermale anhand ihres _mittleren Rangs_ bewertet.\n",
    "* **Mutation**: Eine Möglichkeit Variationen in der Population zu erzeugen, durch zufälliges austauschen von Elementen der Merkmale.\n",
    "* **Elitism**: Eine Möglichkeit die besten Individuen in die nächste Generation zu übertragen. \n",
    "\n",
    "Der hier dargestellte Genetische Algorithmus (GA) wird die folgenden Schritte ausführen:\n",
    "\n",
    "1. Erzeugung einer initialen, zufälligen Population.\n",
    "2. Fitness der Individuen (_Chromosomen_) innerhalb der Population berechnen.\n",
    "3. Selektion des _Mating Pools_, d.h. der fittesten Individuen.\n",
    "4. Kreuzung zur Erzeugung einer neuen Generation.\n",
    "5. Mutation.\n",
    "6. Austausch gegen die neue Population.\n",
    "7. Wiederhole von Schritt 1 bis 6, bis die Abbruchbedingung erfüllt ist.\n",
    "\n",
    "**Aufgaben:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetischer Algorithmus für die Music Feature Selection\n",
    "\n",
    "1. Implementieren Sie die die Merkmalsauswahl mit dem genetischen Algorithmus entsprechend der o.g. Beschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas --upgrade\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random, operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitness-Funktion\n",
    "Die Fitness der Population wird mittels des _mittleren Rangs_, wie im vorherigen Abschnitt berechnet. Je geringer die Größe des mittleren Ranges, desto höher die Bedeutsamkeit der ausgewählten Merkmale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fitness\n",
    "def fitness(df_train, df_test):\n",
    "    euclead_dist = calcEuclideandDist(df_train, df_test)    \n",
    "    return calcMeanRank(euclead_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selektions-Funktion\n",
    "Zur Selektion des _Mating Pools_, d.h. der Elternteile, welche zur Erzeugung der nächsten Generation herangezogen werden sollen, können verschiedene Methoden angewandt werden. Die populärsten Methoden sind _fitness proporionate selection_, ähnlich eines Roulette Rades oder die _tournament selection_. Eine weitere Möglichkeit der Selektion ist die Methode des _elitism_. Hierbei werden die höchst Performer in der Population gegenüber der gesamten Performance der Population bewertet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(popRanked, eliteSize):\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matingPool(population, selection):\n",
    "    return matingPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kreuzungsfunktion\n",
    "Die Kreuzung mittels _crossover_ hat verschiedene Arten an Kreuzungsverfahren. Diese können sein: _blend, one point, two points, uniform_. Mittels __crossover_ soll die nächste Generation aus der selektierten Elternpopulation generiert werden. Man nennt dies auch \"_breeding_\". In diesem Fall wird eine Funktion des _ordered crossover_ verwendet. Dabei werden zufällige Elemente (_Gene_) des ersten Elternteils ausgewählt und mit Elementen / Genen des zweiten Elternteils aufgefüllt, ohne diese zu duplizieren.\n",
    "\n",
    "* Kreuzungsfunktion wie in der KI Vorlesung beim Travelling Salesman Problem. \n",
    "* Man legt einen Kreuzungspunkt fest, nimmt dann für das erste Kind den ersten Kopf wie im Elternteil und für den Tail des ersten Kindes, scannt man den ersten Elternteil und übernimmt die Features die noch nicht drin sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    return child    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generierung der neuen Generation (_offspring population_). Zuerst wird hierbei _elitism_ verwendet, um die besten Merkmale zu erhalten, um diese dann mittels _crossover_ aufzufüllen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossoverPopulation(matingpool, eliteSize):\n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutationsfunktion\n",
    "Es gibt verschiedene Varianten, um Mutation zu erzeugen. Diese sind unter Anderem: _it flip, swap, inverse, uniform, non-uniform, gaussian, shrink_. Mutation hält eine wichtige Funktion für GAs inne, denn diese hilft lokale Komvergenz (_local convergence_), durch das Einführen neuer, noch unbekannter Merkmale, zu vermeiden. Die Einführung neuer Merkmale ermöglicht es einen noch unbekannten Lösungsraum zu erkunden. Da einzelne Merkmale nicht einfach herausgelöscht werden dürfen, wird hier die Methode des _swap mutation_ angewandt. Dies bedeutet, dass mit einer geringen Wahrscheinlichkeit verschiedene Merkmale ihre Lokation austauschen (_swap_) werden. Für ein Individuum kann dies mittels der folgenden Funktion erzeugt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual, mutationRate):\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutatePopulation(population, mutationRate):\n",
    "    return mutatedPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generation der Population\n",
    "Eine zufällige Population (_set of features_) wird aus der gesamten Population herausgelöst. Diese dient als initiale Population für den Generativen Algorithmus (GA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(popSize, featureAmount, featureNames):\n",
    "    # initialize population\n",
    "    population = np.zeros((popSize, featureAmount))\n",
    "    # important use permutation\n",
    "    for i in range(popSize):\n",
    "        population[i, 0:featureAmount]=np.random.permutation(len(featureNames))[:featureAmount]\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeugung der nächsten Generation\n",
    "Eine neue Generation soll mittels der unten aufgeführten Funktion generiert werden. Hierzu werden alle Distanzen, bzw. die Fitness der Merkmale mittels dem _mittleren Rang_ bewertet. Hierauf werden potentielle Eltern aus der Population ausgewählt und ein _Mating Pool_ definiert. Aus diesem kann dann eine neue Generation mittels Kreugung (_crossover_) und Mutation (_mutation_) generiert werden. \n",
    "\n",
    "#### Anmerkung\n",
    "Es ist wichtig zu beachten, dass eine Population eine feste Größe behält. Einzelne, Individuen (_Chromosome_) werden nur gegen fittere Individuen ausgetauscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_population(popRanked, currentGen, eliteSize, mutationRate):\n",
    "    return nextGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetischer Algorithmus\n",
    "\n",
    "Die Populationsgröße, die Anzahl der auszuwählenden Merkmale und die Anzahl der Iterationen sollen als Parameter einstellbar sein.\n",
    "Der Fitnesswert des besten Individuums in der Population soll in jeder Iteration gespeichert werden. Der Verlauf dieses besten Fitness-Wertes über den Fortlauf der Iterationen soll graphisch ausgegeben werden.\n",
    "\n",
    "Ein Pandas Frame, der nur die berechneten wichtigsten Merkmale aus _FeatureFileTrainingAllList1.csv_ enthält soll angelegt und in die csv Datei _subFeaturesTrain1.csv_ geschrieben werden.\n",
    "\n",
    "#### Pseudo Code\n",
    "```\n",
    "START\n",
    "Generate the initial population\n",
    "Compute fitness\n",
    "REPEAT\n",
    "    Selection\n",
    "    Crossover\n",
    "    Mutation\n",
    "    Compute fitness\n",
    "UNTIL population has converged\n",
    "STOP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastEuclidean(x,y):\n",
    "    z=y-x\n",
    "    return math.sqrt(np.dot(z,z))\n",
    "                     \n",
    "def mid_rank(df_train,df_test,similarity): \n",
    "    FeatureFileTrainingDF_scaled = preprocessing.scale(df_train,0)\n",
    "    FeatureFileTestAllDF_scaled = preprocessing.scale(df_test,0)\n",
    "    size = len(FeatureFileTestAllDF_scaled)\n",
    "    rank = 0\n",
    "    ranklist = np.zeros(size)\n",
    "    dct_dist = np.zeros(size)\n",
    "    for i,k in enumerate(FeatureFileTrainingDF_scaled):  \n",
    "        for j,l in enumerate(FeatureFileTestAllDF_scaled):            \n",
    "            dist = similarity(k, l)\n",
    "            dct_dist[j] = dist\n",
    "            \n",
    "        dct_index = np.argsort(dct_dist)\n",
    "        ranklist[i] = np.where(dct_index == i)[0][0]+1    \n",
    "    rank = sum(ranklist)/len(ranklist)\n",
    "    return(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def genAlg(iterations, popSize, anzahlMerkmale, mutationPopulation, label):\n",
    "    kreuzPopulation = 0.99\n",
    "    # array for best fitness-values\n",
    "    bestDist = np.zeros(iterations)\n",
    "    fitness=np.zeros(popSize)\n",
    "    featureNames_fit = np.array(FeatNames)\n",
    "    population = np.zeros((popSize, anzahlMerkmale))\n",
    "    # generate initial population\n",
    "    pop = generate_population(popSize, anzahlMerkmale, FeatNames)\n",
    "    \n",
    "    for j in range(iterations):\n",
    "            # print('------------------- iteration {0} model training -------------------'.format(j))\n",
    "            #Fitnessberechnung:##############################################\n",
    "            for k in range(popSize):\n",
    "                selection = featureNames_fit[population[k].astype(int)]\n",
    "                #print(selection)\n",
    "                df1_temp = df_train_features[selection]\n",
    "                df2_temp = df_test_features[selection]\n",
    "                midRank_temp = mid_rank(df1_temp, df2_temp,  fastEuclidean)\n",
    "                fitness[k] = midRank_temp\n",
    "                #print(midRank_temp)\n",
    "            sortedIndex = fitness.argsort(axis=0)#Indizees der nach ansteigenden Distanzen sortieren\n",
    "            sortedDist = fitness[sortedIndex] # die ansteigend sortiere Distanzen\n",
    "            #print(\"sortedIndex\", sortedIndex)\n",
    "            #print(\"sortedCost\", sortedDist)\n",
    "            bestDist[j] = sortedDist[0] #kleinste Distanz der Iteration abspeichern    \n",
    "            sortedPopulation = population[sortedIndex].astype(int) #sortierung der Population nach ansteigender Distanz    \n",
    "            #print(\"sortedPopulation\", sortedPopulation)\n",
    "            invertedDist = 1/sortedDist #Berechnung der Fitness aus der Distanz\n",
    "            #invertedDist enthält die berechneten Fitness Werte\n",
    "            #print(\"invertedDist\", invertedDist)\n",
    "            #################################################################\n",
    "            \n",
    "            #Selection#######################################################\n",
    "            invertedDistSum = invertedDist.sum()\n",
    "            #print(\"invertedDistSum:\", invertedDistSum)\n",
    "            rn1 = invertedDistSum * np.random.rand() # Zufallszahl ziwschen 0 und 1 * invertedDistSum\n",
    "            #print(\"rn1\", rn1)\n",
    "            found1 = False\n",
    "            index = 1\n",
    "            while not found1:\n",
    "                #print(\"invertedDist[:index].sum(axis=0)\", invertedDist[:index].sum(axis=0))\n",
    "                if rn1 < invertedDist[:index].sum(axis=0): #sum(axis=0): entlang der column summieren\n",
    "                    #print(\"gefunden. index ist:\", index)\n",
    "                    found1=index\n",
    "                else:\n",
    "                    index+=1\n",
    "            found1 = found1-1\n",
    "            equal=True\n",
    "            while equal:\n",
    "                rn2=invertedDistSum * np.random.rand()\n",
    "                #print(\"rn2\", rn2)\n",
    "                found2 = False\n",
    "                index=1\n",
    "                while not found2:\n",
    "                    #print(\"invertedDist[:index].sum(axis=0)\", invertedDist[:index].sum(axis=0))\n",
    "                    if rn2 < invertedDist[:index].sum(axis=0):\n",
    "                        #print(\"gefunden. index ist:\", index)\n",
    "                        found2 = index\n",
    "                    else:\n",
    "                        index+=1\n",
    "                found2=found2-1\n",
    "                if found2 != found1:\n",
    "                    equal = False\n",
    "                #print(\"beides equal?\", equal)\n",
    "            #print(\"ok, weiter gehts\")\n",
    "            parent1 = sortedPopulation[found1]\n",
    "            #print(\"parent1\", parent1)\n",
    "            parent2 = sortedPopulation[found2]\n",
    "            #print(\"parent2\", parent2)\n",
    "            #parent1 und parent2 sind die selektierten Individuen\n",
    "            #################################################################\n",
    "            \n",
    "            #Kreuzung########################################################\n",
    "            crossrn = np.random.rand()\n",
    "            if crossrn < kreuzPopulation:#wenn Wert innerhalb der Kreuzwahrscheinlichkeit gewürfelt -> kreuze\n",
    "                \n",
    "                #berechne random Index bei dem gekreuzt wird\n",
    "                crossIndex = np.random.randint(0, anzahlMerkmale-1)\n",
    "                \n",
    "                head1, tail = np.split(parent1, [crossIndex])\n",
    "                head2, tail = np.split(parent2, [crossIndex])\n",
    "                \n",
    "                # tail\n",
    "                tailind = 0\n",
    "                taillength1 = anzahlMerkmale - len(head1)\n",
    "                tail1 = np.zeros(taillength1, dtype=int)\n",
    "                \n",
    "                for i in range(0, anzahlMerkmale):\n",
    "                    if parent2[i] not in head1 and tailind < taillength1:\n",
    "                        tail1[tailind] = parent2[i]\n",
    "                        tailind = tailind + 1\n",
    "                \n",
    "                tailind = 0\n",
    "                taillength2 = anzahlMerkmale - len(head2)\n",
    "                tail2 = np.zeros(taillength2, dtype=int)\n",
    "                for j in range(0, anzahlMerkmale):\n",
    "                    if parent2[j] not in head2 and tailind < taillength2:\n",
    "                        tail2[tailind] = parent2[j]\n",
    "                        tailind = tailind + 1\n",
    "                \n",
    "                #Kind1 bekommt linken Teil von Parent1 und rechten Teil von Parent2\n",
    "                child1 = np.append(head1, tail1)\n",
    "                #Kind2 bekommt linken Teil von Parent2 und rechten Teil von Parent1\n",
    "                child2 = np.append(head2, tail2)\n",
    "            \n",
    "                #print(\"Kind1:\", child1)\n",
    "                #print(\"Kind2:\", child2)\n",
    "            #################################################################\n",
    "            \n",
    "            #Mutation########################################################\n",
    "            \n",
    "            #Fall child1\n",
    "            mutiere = np.random.rand() < mutationPopulation\n",
    "            #mutiere = True #SPÄTER AUSKOMMENTIEREN!!!!!!!!!!!!!!!\n",
    "            if mutiere:#wenn Wert innerhalb der Mutationswahrscheinlichkeit gewürfelt -> mutiere\n",
    "                #print(\"child1 mutiert\")\n",
    "                #Verändere ein Merkmal des Kindes. Dabei wird das aktuelle Merkmal mit einem zufälligen Merkmal aus FeatNames\n",
    "                #ausgetauscht. Das neue Merkmal soll noch nicht im Kind bereits vorkommen\n",
    "                neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #print(\"neues Merkmal:\", neuesMerkmal)\n",
    "                while neuesMerkmal in child1:\n",
    "                    #Wenn neues Merkmal bereits im Kind enthalten, würfele neu\n",
    "                    neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #wähle ein zufälliges Merkmal des Kindes aus was ersetzt wird\n",
    "                altesMerkmalPos = np.ceil(np.random.rand()*anzahlMerkmale).astype(int)-1\n",
    "                #print(\"Position altes Merkmal:\", altesMerkmalPos)\n",
    "                child1[altesMerkmalPos] = neuesMerkmal #ersetze Merkmal\n",
    "                #print(\"mutiertes child1:\", child1)\n",
    "            \n",
    "            #Fall child2\n",
    "            mutiere = np.random.rand() < mutationPopulation\n",
    "            #mutiere = True #SPÄTER AUSKOMMENTIEREN!!!!!!!!!!!!!!!\n",
    "            if mutiere:#wenn Wert innerhalb der Mutationswahrscheinlichkeit gewürfelt -> mutiere\n",
    "                #print(\"child2 mutiert\")\n",
    "                #Verändere ein Merkmal des Kindes. Dabei wird das aktuelle Merkmal mit einem zufälligen Merkmal aus FeatNames\n",
    "                #ausgetauscht. Das neue Merkmal soll noch nicht im Kind bereits vorkommen\n",
    "                neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #print(\"neues Merkmal:\", neuesMerkmal)\n",
    "                while neuesMerkmal in child2:\n",
    "                    #Wenn neues Merkmal bereits im Kind enthalten, würfele neu\n",
    "                    neuesMerkmal = np.ceil(np.random.rand()*(len(FeatNames))).astype(int)-1\n",
    "                #wähle ein zufälliges Merkmal des Kindes aus was ersetzt wird\n",
    "                altesMerkmalPos = np.ceil(np.random.rand()*anzahlMerkmale).astype(int)-1\n",
    "                #print(\"Position altes Merkmal:\", altesMerkmalPos)\n",
    "                child2[altesMerkmalPos] = neuesMerkmal #ersetze Merkmal\n",
    "                #print(\"mutiertes child2:\", child2)\n",
    "            \n",
    "            #child1 und child2 sind die Resultate der Mutation #######################\n",
    "            \n",
    "            #Ersetze die schlechtesten zwei Individuen mit den Kindern, falls die Neuen besser sind#########\n",
    "            merkmaleChild1 = featureNames_fit[child1]\n",
    "            #print(\"merkmaleChild1\", merkmaleChild1)\n",
    "            df1_child1 = df_train_features[merkmaleChild1]\n",
    "            df2_child1 = df_test_features[merkmaleChild1]\n",
    "            midRank_child1 = mid_rank(df1_child1,df2_child1, fastEuclidean)\n",
    "            \n",
    "            merkmaleChild2 = featureNames_fit[child2]\n",
    "            #print(\"merkmaleChild2\", merkmaleChild2)\n",
    "            df1_child2 = df_test_features[merkmaleChild2]\n",
    "            df2_child2 = df_train_features[merkmaleChild2]\n",
    "            midRank_child2 = mid_rank(df1_child2,df2_child2, fastEuclidean)\n",
    "            \n",
    "            replace1=False\n",
    "            replace2=False\n",
    "            index = popSize -1\n",
    "            while index > 0:\n",
    "                if sortedDist[index]>midRank_child1 and not replace1:\n",
    "                    if not np.ndarray.any(np.ndarray.all(child1==sortedPopulation, axis=1)):\n",
    "                        sortedPopulation[index]= child1\n",
    "                    replace1=True\n",
    "                elif sortedDist[index]>midRank_child2 and not replace2:\n",
    "                    if not np.ndarray.any(np.ndarray.all(child2==sortedPopulation, axis=1)):\n",
    "                        sortedPopulation[index]= child2\n",
    "                    replace2=True\n",
    "                if replace1 and replace2:\n",
    "                    break\n",
    "                index=index-1\n",
    "            population=sortedPopulation\n",
    "            #print(\"Population am Ende der Iteration:\", population)\n",
    "            #print(\"bestDist:\", bestDist)\n",
    "            \n",
    "    #Graphische Anzeige#########################################\n",
    "    bestIndividuum = featureNames_fit[population[0]]\n",
    "    print(\"bestIndividuum \", bestIndividuum)\n",
    "    subFeaturesTrain1DF = df_train_features[bestIndividuum]\n",
    "    subFeaturesTrain1DF.to_csv('./subFeaturesTrain1.csv', sep=\",\")\n",
    "    print(\"Best mid rank:\", bestDist[-1])\n",
    "    print(\"Population \", population[0])\n",
    "    plt.subplot(122)\n",
    "    plt.grid(True)\n",
    "    plt.plot(range(iterations), bestDist, label=label)\n",
    "    plt.legend()\n",
    "    plt.savefig('genetic_algorithm_{}.png'.format(label))\n",
    "    plt.show()\n",
    "    return bestDist[-1]\n",
    "    ############################################################\n",
    "\n",
    "#genAlg(100, 100, 10, 0.1,'test') #iterationen, populationsize, #merkmale, mutationsRate, plotlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training des Genetischen Algorithmus\n",
    "Hierfür wird eine variierende Anzahl an Merkmalen ausgewählt, um den Algorithmus, sowie die daraus generierten Modelle auf die beste Anzahl an Merkmalen zu untersuchen. \n",
    "\n",
    "Während die Merkmale _iterations_, _popSize_, sowie _mutationPopulation_ für eine Vergleichbarkeit der Ergebnisse immer konstant gehalten werden, wird die Anzahl der Merkmale in immer gleich bleibenden Schritten zwischen dem Wert 10 bis 30 variiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'power1' 'power4' 'amp10kurt' 'power7' 'amp10dkurt'\n",
      " 'amp100std' 'power10' 'power6' 'amp10skew']\n",
      "Best mid rank: 1.9\n",
      "Population  [ 0 32 35 11 38 15 17 41 37 10]\n",
      "Distanz bei 10 Merkmalen:  1.9\n",
      "bestIndividuum  ['amp1mean' 'amp10dskew' 'power4' 'amp100dkurt' 'amp100dstd' 'amp1000dstd'\n",
      " 'power10' 'power6' 'amp10dstd' 'amp10skew' 'power7']\n",
      "Best mid rank: 1.6\n",
      "Population  [ 0 14 35 23 21 29 41 37 13 10 38]\n",
      "Distanz bei 11 Merkmalen:  1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'power7' 'amp10kurt' 'amp1dskew' 'power8' 'amp100dstd'\n",
      " 'amp1000std' 'amp10dskew' 'power1' 'amp10dkurt' 'power9' 'amp10skew']\n",
      "Best mid rank: 1.5333333333333334\n",
      "Population  [ 0 38 11  6 39 21 25 14 32 15 40 10]\n",
      "Distanz bei 12 Merkmalen:  1.5333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'amp1000std' 'power10' 'amp100std' 'power1' 'power6'\n",
      " 'amp1dskew' 'amp100dstd' 'power9' 'power7' 'amp10skew' 'amp100dkurt'\n",
      " 'power8']\n",
      "Best mid rank: 1.4333333333333333\n",
      "Population  [ 0 25 41 17 32 37  6 21 40 38 10 23 39]\n",
      "Distanz bei 13 Merkmalen:  1.4333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1dskew' 'power7' 'power1' 'amp10dskew' 'power9' 'amp1000std' 'power4'\n",
      " 'amp100dstd' 'amp100kurt' 'amp100std' 'amp10dkurt' 'amp10skew' 'power8'\n",
      " 'power10']\n",
      "Best mid rank: 1.5\n",
      "Population  [ 6 38 32 14 40 25 35 21 19 17 15 10 39 41]\n",
      "Distanz bei 14 Merkmalen:  1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'amp100dstd' 'amp1std' 'amp1dskew' 'amp10mean' 'amp10skew'\n",
      " 'power6' 'power7' 'power8' 'power2' 'power4' 'amp100dkurt' 'power10'\n",
      " 'amp10dskew' 'amp1mean']\n",
      "Best mid rank: 1.4833333333333334\n",
      "Population  [ 0 21  1  6  8 10 37 38 39 33 35 23 41 14  0]\n",
      "Distanz bei 15 Merkmalen:  1.4833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'amp1mean' 'amp1mean' 'power4' 'amp10skew' 'power7'\n",
      " 'amp1000std' 'power2' 'power9' 'power1' 'amp1dskew' 'amp10dskew'\n",
      " 'amp100std' 'amp1000dstd' 'amp1000mean' 'power10']\n",
      "Best mid rank: 1.5\n",
      "Population  [ 0  0  0 35 10 38 25 33 40 32  6 14 17 29 24 41]\n",
      "Distanz bei 16 Merkmalen:  1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'amp10kurt' 'amp1000dstd' 'power7' 'amp1dskew' 'power8'\n",
      " 'power4' 'amp10dskew' 'amp100std' 'amp10dstd' 'amp10dkurt' 'power1'\n",
      " 'amp100dstd' 'amp100mean' 'amp10skew' 'power5' 'power9']\n",
      "Best mid rank: 1.5833333333333333\n",
      "Population  [ 0 11 29 38  6 39 35 14 17 13 15 32 21 16 10 36 40]\n",
      "Distanz bei 17 Merkmalen: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.5833333333333333\n",
      "bestIndividuum  ['amp1mean' 'amp1mean' 'power7' 'amp10skew' 'power8' 'power10' 'power1'\n",
      " 'power4' 'amp1skew' 'amp100mean' 'amp1000dstd' 'amp100dkurt' 'amp100std'\n",
      " 'amp10std' 'amp1mean' 'amp1mean' 'amp1mean' 'amp1mean']\n",
      "Best mid rank: 1.4833333333333334\n",
      "Population  [ 0  0 38 10 39 41 32 35  2 16 29 23 17  9  0  0  0  0]\n",
      "Distanz bei 18 Merkmalen:  1.4833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'amp1mean' 'power10' 'amp1000std' 'power2' 'amp1dskew'\n",
      " 'power1' 'power9' 'amp1skew' 'amp100dstd' 'amp100std' 'amp10dstd'\n",
      " 'power6' 'power8' 'amp10skew' 'amp100dkurt' 'amp1mean' 'amp1mean'\n",
      " 'amp1mean']\n",
      "Best mid rank: 1.55\n",
      "Population  [ 0  0 41 25 33  6 32 40  2 21 17 13 37 39 10 23  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanz bei 19 Merkmalen:  1.55\n",
      "bestIndividuum  ['amp1mean' 'power1' 'power8' 'amp100dmean' 'amp100std' 'power4' 'power2'\n",
      " 'amp100dstd' 'amp10dstd' 'amp1dskew' 'amp1000dstd' 'amp100mean'\n",
      " 'amp10skew' 'power9' 'amp1skew' 'amp10dskew' 'power10' 'power7' 'power6'\n",
      " 'amp1000std']\n",
      "Best mid rank: 1.4833333333333334\n",
      "Population  [ 0 32 39 20 17 35 33 21 13  6 29 16 10 40  2 14 41 38 37 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanz bei 20 Merkmalen:  1.4833333333333334\n",
      "bestIndividuum  ['amp1mean' 'amp1mean' 'power1' 'power4' 'amp1dskew' 'amp10dskew'\n",
      " 'amp1000std' 'power7' 'power9' 'power8' 'amp10skew' 'amp100dstd'\n",
      " 'amp100dkurt' 'power2' 'power6' 'amp1000skew' 'power10' 'amp1skew'\n",
      " 'amp1mean' 'amp1mean' 'amp1mean']\n",
      "Best mid rank: 1.4166666666666667\n",
      "Population  [ 0  0 32 35  6 14 25 38 40 39 10 21 23 33 37 26 41  2  0  0  0]\n",
      "Distanz bei 21 Merkmalen:  1.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestIndividuum  ['amp1mean' 'power8' 'amp1dskew' 'amp100std' 'power2' 'amp100dstd'\n",
      " 'amp10skew' 'power7' 'power6' 'power9' 'amp10dskew' 'amp100mean' 'power4'\n",
      " 'amp1skew' 'amp1mean' 'amp1mean' 'amp1mean' 'amp1mean' 'amp1mean'\n",
      " 'amp1mean' 'amp1mean' 'amp1mean']\n",
      "Best mid rank: 1.4333333333333333\n",
      "Population  [ 0 39  6 17 33 21 10 38 37 40 14 16 35  2  0  0  0  0  0  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanz bei 22 Merkmalen:  1.4333333333333333\n",
      "bestIndividuum  ['amp1mean' 'amp100dstd' 'amp10dstd' 'amp100dmean' 'power5' 'amp1dskew'\n",
      " 'amp100dkurt' 'amp10skew' 'power2' 'power1' 'amp1000std' 'amp1000dskew'\n",
      " 'amp1skew' 'amp100skew' 'amp10dskew' 'amp10std' 'amp1000dstd' 'power9'\n",
      " 'power4' 'amp100kurt' 'power10' 'power7' 'amp10dkurt']\n",
      "Best mid rank: 1.5833333333333333\n",
      "Population  [ 0 21 13 20 36  6 23 10 33 32 25 30  2 18 14  9 29 40 35 19 41 38 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janina\\anaconda3\\envs\\conda_env\\lib\\site-packages\\ipykernel_launcher.py:193: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanz bei 23 Merkmalen:  1.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "model_result = []\n",
    "\n",
    "for merkmal in range(10, 30):\n",
    "    m = genAlg(2000, 50, merkmal, 0.05, \"{0}_features_genetic_algorithm: \".format(merkmal))\n",
    "    model_result.append([merkmal, m])\n",
    "    print(\"Distanz bei {0} Merkmalen: \".format(merkmal), m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Music Feature Selection\n",
    "2. Implementieren und beschreiben Sie kurz das Konzept ihrer Kreuzungs- und Mutationsfunktion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kreuzung:\n",
    "\n",
    "Indivduen mit niedriger Distanz bzw. mit gutem Fitnesswert werden miteinander gekreuzt. Dabei wird ein zufälliger Schnittpunkt zur Vereinigung der Elternvektoren genutzt. Die Chromosome werden an dieser Stelle geteilt und miteinander vertauscht.\n",
    "\n",
    "##### Mutation:\n",
    "\n",
    "Mit niedriger Wahrscheinlichkeit wird ein Wert zufällig verändert.\n",
    "\n",
    "( _Siehe den Code im oberen Abschnitt._ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bestimmen Sie eine möglichst kleine Merkmalsuntermenge mit einem möglichst guten mittleren Rang? Geben Sie sowohl die gefundenen wichtigsten Merkmale als auch den zugehörigen mittleren Rang an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine möglichtst kleine Merkmalsuntermenge mit möglichst gutem _mittlerem Rang_ konnte bei 20 Merkmalen gefunden. Der daraus resultierende mittlere Rang beträgt 1.35, wobei die wichtigste Merkmale sind:\n",
    "\n",
    "```\n",
    "'power7' 'amp1mean' 'amp1000std' 'amp10kurt' 'power2' 'power1' 'amp10skew' \n",
    "'amp1dskew' 'amp1000mean' 'amp10mean' 'power9' 'power4' 'amp1dskew' 'power7' \n",
    "'amp10skew' 'amp100std' 'amp10dskew' 'power8' 'power6' 'power10'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Um wieviel verschlechtert sich der Mittlere Rang, wenn nur die 10 wichtigsten Merkmale benutzt werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.534 - 1.35 = 0.184\n",
    "\n",
    "Der Rang verschlechtert sich nur um 0.184. Der Unterschied zwischen 20 und 10 Merkmalen fällt nicht groß aus. Der Informationsgewinn bei zusätzlichen Features ist somit sehr gering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untersuchung der Merkmale\n",
    "Des weiteren wird der Algorithmus untersucht auf die Variation der Mutationswahrscheinlichkeit. Diese findet in Abständen zwischen _[0.01, 0.05, 0.1, 0.2]_ statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mutation = [0.01, 0.05, 0.1, 0.2]\n",
    "for f in pop_mutation:\n",
    "    result = genAlg(2000, 50, 13, f, \"{0}_features_genetic_algorithm: \".format(f))\n",
    "    print(\"Distanz bei {0} Merkmalen: \".format(result), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering und automatische Playlistgenerierung\n",
    "Implementieren Sie ein hierarchisches Clustering aller Subsequenzen in _subFeaturesTrain1.csv_. Diese _.csv_-Datei enthält nur die im vorigen Schritt ermittelten wichtigsten Merkmale. Das hierarchische Clustering ist in einem Dendrogram der Art wie in der unten gegebenen Abbildung zu visualisieren.\n",
    "\n",
    "Die gefundenen Cluster sind mit den zugehörigen Musiktiteln in der Konsole auszugeben. \n",
    "![Abbildung Music Clustering](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/playlistCluster.png \"Music Clustering\")\n",
    "\n",
    "### Das Hierarchische Clustering\n",
    "\n",
    "Das Hierarchische Clustering ist ein Typ des unüberwachten Lernens (engl., _Unsupervised Learning_). Dieser wird angewandt, um nicht gelabelte Datenpunkte zu clustern. Ähnlich dem K-means Clustering Algorithmus grupiert der Hierarchische Clustering Algorithmus Datenpunkte zusammen, welche ähnliche Charakteristiken aufweisen. In manchen Fällen kann das Ergebnis des hierarchischen, als auch K-means Clustering Algorithmus daher ähnliche sein. Die Hierarchie dieser Cluster wird als Baum Strukture (_Dendogram_) dargestellt. Die Wurzel dieses Baumes stellt das einzigartige Cluster dar, welches alle Stichproben an Datenpunkte (engl., _samples_) vereint. In den Blättern dagegen finden sich die einzelnen Cluster, die nur einen Datenpunktsatz enthalten.\n",
    " \n",
    "### Agglomerierendes und spaltendes hierarchisches Clustering\n",
    "Es gibt zwei Arten von hierarchischem Clustering, welche als _agglomerierend_ und _spaltend_ (engl., _agglomerative and divisive_) bezeichnet werden. Beim _agglomerierenden_ hierarchischen Clustering wird ein _bottom-up_ Vorgehen, beginnend von den Datenpunkten angwandt, während im _top-down_ Vorgehen alle Datenpunkte als ein großes Cluster betrachtet werden. Hierbei wird das Vorgehen des Spaltens (engl., _dividing_ ) des gesamten Clusters in kleinere Cluster vorgenommen. \n",
    "\n",
    "* **Agglomerativ** - Bottom-up-Ansatz. Beginnen Sie mit vielen kleinen Clustern und fügen Sie diese zu größeren Clustern zusammen.\n",
    "* **Trennend** - Ansatz von oben nach unten. Beginnen Sie mit einem einzelnen Cluster und zerlegen Sie ihn dann in kleinere Cluster.\n",
    "\n",
    "### Das Verknüphungskriterium (_linkage criteria_)\n",
    "Das Verknüpfungskriterium bestimmt die für die Zusammenführungsstrategie verwendete Metrik:\n",
    "\n",
    "* _Ward_ minimiert die Summe der quadrierten Differenzen in allen Clustern. Es handelt sich um einen Varianz-minimierenden Ansatz und ähnelt in diesem Sinne der k-Mittelwert-Zielfunktion, wird aber mit einem agglomerierenden hierarchischen Ansatz angegangen.\n",
    "\n",
    "* _Maximale oder vollständige Verknüpfung_ minimiert den maximalen Abstand zwischen den Beobachtungen von Paaren von Clustern.\n",
    "\n",
    "* _Durchschnittliche Verknüpfung_ minimiert den Durchschnitt der Abstände zwischen allen Beobachtungen von Haufenpaaren.\n",
    "\n",
    "* _Einzelverknüpfung_ minimiert den Abstand zwischen den nächsten Beobachtungen von Haufenpaaren.\n",
    "\n",
    "\n",
    "#### Umsetzung des agglomerierenden Clusterings (_Agglomerative Clustering_)\n",
    "\n",
    "Der _FeatureAgglomeration_ Cluster Algorithmus ist ähnlich dem _Agglomerative_ Clustering, jedoch werden rekursiv Merkmale anstelle von Stichproben zusammengeführt. Der _agglomerierende, hierarchische Clustering Algorithmus_ wird im Folgenden mittels der Scikit-Learn Library umgesetzt. \n",
    "\n",
    "#### Pseudo Code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben:**\n",
    "\n",
    "1. Optimieren Sie für die Anwendung des Hierarchischen Clustering Algorithmus die Parameter\n",
    "\n",
    "    1. metric (Ähnlichkeitsmaß), in diesem Fall 'affinity'\n",
    "    2. linkage method, in diesem Fall 'linkage'\n",
    "    3. Clusteranzahl, in diesem Fall 'n_clusters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music_features = pd.read_csv(\"./subFeaturesTrain1.csv\", sep=\",\", delimiter=None, header='infer', names=None, index_col=None)\n",
    "df_music_features =  df_music_features.rename(columns={'Unnamed: 0': 'music_title'})\n",
    "df_music_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all music labels\n",
    "dict_music_label = df_music_features.music_title.to_dict()\n",
    "music_label = {v: k for k, v in dict_music_label.items()}\n",
    "\n",
    "df_music_features_copy = df_music_features.copy()\n",
    "df_music_features_copy.music_title = df_music_features.music_title.map(music_label)\n",
    "df_music_features_copy.set_index('music_title', inplace=True)\n",
    "df_music_features_copy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skalierung der Input Variablen\n",
    "Um einen _Bias_ des Models zu verhindern werden die Datensätze normalisiert, sodass alle die selbe Skalierung aufweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# data preprocessing to normalize the data to bring them to the same scale\n",
    "data_scaled = preprocessing.scale(df_music_features_copy)\n",
    "data_scaled = pd.DataFrame(data_scaled, index=df_music_features.index, columns=df_music_features_copy.columns)\n",
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenanalyse mittels Heatmap\n",
    "Mittels einer Heatmap können die Datensätze auf deren Verteilung und Ähnlichkeit zueinander untersucht werden. Je stärker die Felder gelb eingefärbt sind, desto größer ist der Wert dieses Merkmals. Dies verhält sich ebenso umgekehrt mit dunkel-blau eingefärbten Werten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "ax.axes.set_title(\"Heatmap of features from music samples\", fontsize=24, y=1.01)\n",
    "ax.set(xlabel='Feature X', ylabel='Importance Y');\n",
    "sns.heatmap(data_scaled, annot=True, fmt=\"g\", cmap='viridis', ax=ax)\n",
    "plt.savefig('heatmap_music_feature_dist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "def create_dendogram(df_data, affinity, labels):\n",
    "    #linkage matrix encoding hierarchical clustering\n",
    "    Z = linkage(df_data, affinity) \n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.title('Hierarchical Clustering Dendrogram', fontsize=20)\n",
    "    plt.xlabel('Calculated distance, method {}'.format(affinity), fontsize=16)\n",
    "    plt.ylabel('Music features per title', fontsize=16)\n",
    "    # create dendogram\n",
    "    R = dendrogram(Z, orientation=\"right\", labels=labels)\n",
    "    \n",
    "    # define graph spec\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(axis='x', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "    plt.savefig('dendrogram {}.png'.format(affinity))\n",
    "    plt.show()\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unterschiedliche Affinity und Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine', 'precomputed']\n",
    "method_linkage = ['ward', 'complete', 'average', 'single']\n",
    "labels = df_music_features.music_title.tolist()\n",
    "leaves_dict = {}\n",
    "# Create dendograms with various methods\n",
    "for method in method_linkage:\n",
    "    leaves1 = create_dendogram(data_scaled, method, labels)\n",
    "    leaves_dict[method] = leaves1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Für welche Parameterkonstellation erlangen Sie das für Sie subjektiv betrachtet günstigste Ergebnis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjektiv betrachtet ergeben die generierten Cluster (Playlists) Sinn. Künstler werden größtenteils in eine Playlist zusammengefasst, mit wenigen anderen Künstlern z.B. eine Playlist mit 15 Adele Songs und mit nur einem einzigen Lana Del Rey Song. Zudem kann man Ausreißer-Cluster anhand von kleinen Playlists erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Überlegen Sie sich Ansätze um diese Art der Musikgruppierung zu verbessern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am nahe liegendsten wäre die Extraktion von weiteren Features wie z.B. Sprache, BPM, Spieldauer der Songs. Außerdem könnte man die Clustergröße anhand von einer Mindest- oder Maximalanzahl von Songs vordefinieren, um z.B. eine Playlist mit einer gewissen Spieldauer zu erstellen. Grundsätzlich ist es möglich ein anderes Verfahren zur Clusterbildung zu verwenden (z.B. K-Means).\n",
    "\n",
    "Fazit:\n",
    "\n",
    "Ein Durchlauf des genetischen Algorithmus dauert sehr lange. Dies hat das Testen und Entwickeln sehr zeitaufwendig gemacht! Wir hätten diesbezüglich von Anfang an mit Multithreading arbeiten sollen, stattdessen haben wir die Performance durch eine andere Euklidfunktion verbessert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Dictionary _R_, das von der Scipy Funktion _dendrogram()_ zurück gegeben wird, enthält Informationen über  das _Dendrogram_ und damit auch eine Liste an Werten der geclusterten Musikstüclke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusatz: Visuelle Analyse der Clusteranzahl mittels Dendogram\n",
    "Die Daten können mittels einem Dendogram untersucht werden. Dies gibt Aufschluss darüber, wie viele Cluster aus dem gesamten Datensatz (enlg., _sample_ ) im Optimum hervorgebracht werden können. Die _x-Achse_ enthält die Datensätze und die _y-Achse_ stellt den Abstand (bzw. Unähnlichkeit) zwischen den Datensätzen dar. Je größer der Abstand, desto unähnlicher sind sich die Datensätze und umgekehrt. Die senkrechte Linie mit dem maximalen Abstand ist die blaue Linie und daher kann in diesem Beispiel ein Schwellenwert von _t=5_ festgelegt werden, um hier das Dendrogramm visuell zu schneiden. Der Schwellenwert bei _t=5_ (engl., _threshold_ ) wird durch eine gestrichtelte Linie im _Dendogram_ dargestellt. Durch den Schnitt dieser mit drei zusammen laufenden Cluster Linien (engl., _fusions_) lässt sich erkennen, dass sich nun _n=3_ Cluster bilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hierarchical_cluster(data, method):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(\"Cluster analysis Dendrogram, method={}\".format(method)) \n",
    "    plt.xlabel('Music Titles')\n",
    "    plt.ylabel('Euclidean distances')\n",
    "    dend = shc.dendrogram(shc.linkage(data, method))\n",
    "    # plot the line to make the threshhold visible\n",
    "    plt.axhline(y=5, color='r', linestyle='--')\n",
    "    plt.axhline(y=3, color='r', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Methode=_'ward'_ die besten Ergebnisse erzielt hat, wird diese auch in dem folgenden Versuch angewandt. Das Ähnlichkeitsmaß ist auch hier die _euklidsche Distanz_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hierarchical_cluster(data_scaled, 'ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erkenntnis Dendrogram\n",
    "Visuelle Untersuchung des Cluster Baumes in einem _Dendogram_. Im untersten Knoten, dem Blatt (_engl., leave_) werden die ähnlichsten Merkmale in einem Cluster zusammen gefasst. Diese Cluster erhalten die Label zwischen _1-n_ der festgelegten Cluster Anazhl _n_. \n",
    "\n",
    "#### Ausreißer erkennen ( _outlier detection_ )\n",
    "In dem aktuellen Graphen sind keine Ausreißer erkennbar. Diese könnten normalerweise anhand von nicht paarweise vorkommenden Zweigen ( _branches_ ) ausgemacht werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainieren des Agglomerative Clustering Algorithmus\n",
    "Der Algorithmus benötigt keine initiale Angabe der Cluster Anzahl _k_, wie der k-means Clustering Algorithmus. \n",
    "\n",
    "#### Vorgehen\n",
    "Zunächst wird jeder Punkt als ein separates Cluster betrachtet, dann werden die Punkte rekursiv in Abhängigkeit von der Entfernung zwischen ihnen gebündelt. Die Datenpunkte werden so gruppiert, dass der Abstand zwischen den Datenpunkten innerhalb eines Clusters minimal und der Abstand zwischen den Punkten innerhalb verschiedener Clusters maximal ist. Häufig verwendete Entfernungsmaße sind die euklidische Distanz, die Manhattan-Distanz oder die Mahalanobis-Distanz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerativeCluster(data, n_clusters, affinity, linkage):\n",
    "    agglo_cluster_model = AgglomerativeClustering(n_clusters, affinity, linkage)\n",
    "    return agglo_cluster_model.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 1. Optimieren Sie für die Anwendung des Hierarchischen Clustering Algorithmus die Parameter\n",
    "\n",
    "- metric (Ähnlichkeitsmaß), in diesem Fall 'affinity'\n",
    "- linkage method, in diesem Fall 'linkage'\n",
    "- Clusteranzahl, in diesem Fall 'n_clusters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lables = agglomerativeCluster(data_scaled, n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "cluster_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative = pd.DataFrame(cluster_lables)\n",
    "df_music_features.insert((df_music_features.shape[1]), 'agglomerative', agglomerative)\n",
    "df_music_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(df_data, n_cluster):\n",
    "    music_cluster = []\n",
    "    for n in range(1, n_cluster):\n",
    "        playlist_recom = df_data.loc[df_data['agglomerative'] == n]\n",
    "        music_cluster.append(playlist_recom)\n",
    "        print('Cluster{0}: {1}'.format(n, playlist_recom))\n",
    "    return music_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_cluster = get_cluster(df_music_features, 3)\n",
    "music_cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
